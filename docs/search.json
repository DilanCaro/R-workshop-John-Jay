[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"ready embark exciting journey world data analysis statistical exploration? Imagine power unlock hidden insights within vast datasets, create stunning visualizations, make data-driven decisions can shape future. Welcome world R programming! R just language; ’s key uncovering stories data tell. Whether ’re budding data scientist, curious researcher, someone simply loves solving puzzles, R offers thrilling adventure ’ll learn command data precision creativity. Get ready amazed endless possibilities R join global community data enthusiasts reshaping world, one analysis time.website, resources, examples practice master R.","code":""},{"path":"index.html","id":"objectives","chapter":"Welcome","heading":"Objectives","text":"","code":""},{"path":"index.html","id":"session-1-r-basics-2-hours","chapter":"Welcome","heading":"Session 1: R Basics (2 hours)","text":"","code":""},{"path":"index.html","id":"part-1-introduction-to-r","chapter":"Welcome","heading":"Part 1: Introduction to R","text":"R use ?Installing R RStudioBasic RStudio layout functionality","code":""},{"path":"index.html","id":"part-2-r-fundamentals","chapter":"Welcome","heading":"Part 2: R Fundamentals","text":"R calculatorVariables data types (numeric, character)Basic arithmetic operations","code":""},{"path":"index.html","id":"part-3-data-structures","chapter":"Welcome","heading":"Part 3: Data Structures","text":"Vectors: Creating, indexing, operationsData frames: Creating exploring data framesImporting exporting data (CSV files)","code":""},{"path":"index.html","id":"part-4-data-manipulation","chapter":"Welcome","heading":"Part 4: Data Manipulation","text":"Subsetting filtering dataAdding, removing, renaming columnsBasic data summary exploration","code":""},{"path":"index.html","id":"part-5-basic-data-visualization","chapter":"Welcome","heading":"Part 5: Basic Data Visualization","text":"Creating simple plots using plot(), hist(), pie(),barplot(),boxplot()","code":""},{"path":"index.html","id":"session-2-intermediate-r-i","chapter":"Welcome","heading":"Session 2: Intermediate R I","text":"","code":""},{"path":"index.html","id":"part-1-functions-and-control-structures","chapter":"Welcome","heading":"Part 1: Functions and Control Structures","text":"Writing using functionsIf statements loops ()","code":""},{"path":"index.html","id":"part-2-data-wrangling-cleaning-and-transformation","chapter":"Welcome","heading":"Part 2: Data Wrangling: Cleaning and Transformation","text":"Reshaping data using dplyr functions (filter, arrange, mutate, summarize)Handling missing data","code":""},{"path":"index.html","id":"session-3-intermediate-r-ii","chapter":"Welcome","heading":"Session 3: Intermediate R II","text":"","code":""},{"path":"index.html","id":"part-1-advanced-data-visualization","chapter":"Welcome","heading":"Part 1: Advanced Data Visualization","text":"Creating customized plots ggplot2Adding titles, labels, themes plots","code":""},{"path":"index.html","id":"part-2-statistical-analysis","chapter":"Welcome","heading":"Part 2: Statistical Analysis","text":"Introduction hypothesis testing statistical testsPerforming t-tests chi-squared tests","code":""},{"path":"index.html","id":"optional-part-3-working-with-dates-and-times","chapter":"Welcome","heading":"(Optional) Part 3: Working with Dates and Times","text":"Handling date time data RCommon date time functions","code":""},{"path":"index.html","id":"optional-session-4-advanced-r","chapter":"Welcome","heading":"(optional) Session 4: Advanced R","text":"","code":""},{"path":"index.html","id":"part-1-advanced-data-manipulation-with-dplyr","chapter":"Welcome","heading":"Part 1: Advanced Data Manipulation with dplyr","text":"Grouping summarizing dataJoining merging datasets","code":""},{"path":"index.html","id":"part-2-text-data-processing","chapter":"Welcome","heading":"Part 2: Text Data Processing","text":"Manipulating analyzing text data using regular expressionsText mining basics","code":""},{"path":"index.html","id":"part-3-building-predictive-models","chapter":"Welcome","heading":"Part 3: Building Predictive Models","text":"Introduction machine learning RCreating predictive models caret","code":""},{"path":"index.html","id":"part-4-bookdown-using-r-markdown-to-create-books","chapter":"Welcome","heading":"Part 4: Bookdown: Using R markdown to create books","text":"Introduction Bookdown PackageCreating simple bookdown book","code":""},{"path":"index.html","id":"part-5-version-control-and-collaboration","chapter":"Welcome","heading":"Part 5: Version Control and Collaboration","text":"Using Git GitHub version control collaboration R projects","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"R Basics","heading":"R Basics","text":"first session, lay foundation R journey. ’ll start introduction R, delving ’s popular choice among data enthusiasts. ’ll learn install R RStudio, user-friendly integrated development environment (IDE). ’ll explore basic layout functionality RStudio, setting stage coding adventures.’ll dive R’s fundamentals, treating trusty calculator. ’ll discover various data types, numeric character, grasp essential arithmetic operations. Moving forward, ’ll explore R’s data structures, including vectors data storage data frames structured datasets. ’ll also become adept importing exporting data using common formats like CSV files.won’t stop . next part session data manipulation. ’ll learn subset filter data, add, remove, rename columns, gain skills basic data summarization exploration. Finally, ’ll wrap basic data visualization, ’ll create simple plots visually represent data.","code":""},{"path":"part-i-introduction-to-r.html","id":"part-i-introduction-to-r","chapter":"Part I: Introduction to R","heading":"Part I: Introduction to R","text":"","code":""},{"path":"part-i-introduction-to-r.html","id":"what-is-r","chapter":"Part I: Introduction to R","heading":"What is R ?","text":"R programming language open-source software environment widely used statistical computing, data analysis, graphics. created Ross Ihaka Robert Gentleman University Auckland, New Zealand, early 1990s now maintained R Development Core Team. R particularly popular among statisticians, data scientists, researchers extensive statistical graphical capabilities.brief sentence: R dialect S.","code":""},{"path":"part-i-introduction-to-r.html","id":"what-is-s","chapter":"Part I: Introduction to R","heading":"What is S ?","text":"S language, developed John Chambers others Bell Telephone Laboratories, began 1976 internal statistical analysis tool, originally based Fortran libraries. evolved significantly time: 1988, rewritten C, leading system akin present form (Version 3).statistical analysis capabilities S detailed 1988 book “Statistical Models S” (white book) Chambers Hastie. current version, Version 4, released 1998 documented Chambers’ “Programming Data” (green book), remains use. ownership S changed hands several times: Bell Labs licensed StatSci (later Insightful Corp.) 1993, Insightful bought Lucent 2004, series acquisitions, TIBCO Software Inc. owned exclusively developed S since 2008. Insightful added features, including GUIs, marketed S-PLUS. Despite changes, core S language remained largely unchanged since 1998, year earned prestigious ACM Software System Award.","code":""},{"path":"part-i-introduction-to-r.html","id":"key-features-and-characteristics-of-r","chapter":"Part I: Introduction to R","heading":"Key features and characteristics of R :","text":"Data Analysis Statistics: R provides wide range statistical techniques libraries data analysis, hypothesis testing, regression analysis, clustering, . ’s known flexibility handling data conducting statistical experiments.Data Analysis Statistics: R provides wide range statistical techniques libraries data analysis, hypothesis testing, regression analysis, clustering, . ’s known flexibility handling data conducting statistical experiments.Data Visualization: R offers powerful tools creating variety high-quality data visualizations, including scatterplots, bar charts, histograms, heatmaps. ggplot2 package, particular, popular choice creating customized graphics.Data Visualization: R offers powerful tools creating variety high-quality data visualizations, including scatterplots, bar charts, histograms, heatmaps. ggplot2 package, particular, popular choice creating customized graphics.Open Source: R open-source software, means freely available anyone use, modify, distribute. led vibrant community users developers contribute packages extensions enhance functionality.Open Source: R open-source software, means freely available anyone use, modify, distribute. led vibrant community users developers contribute packages extensions enhance functionality.Package System: R rich ecosystem packages (libraries) extend core functionality. packages cover wide range domains, machine learning time series analysis bioinformatics geospatial data analysis. Users can easily install use packages tailor R specific needs.Package System: R rich ecosystem packages (libraries) extend core functionality. packages cover wide range domains, machine learning time series analysis bioinformatics geospatial data analysis. Users can easily install use packages tailor R specific needs.Cross-Platform: R runs various operating systems, including Windows, macOS, Linux, making accessible wide range users.Cross-Platform: R runs various operating systems, including Windows, macOS, Linux, making accessible wide range users.Command-Line Interface: R primarily uses command-line interface, although graphical user interfaces (GUIs) available, RStudio, provide user-friendly environment coding data analysis.Command-Line Interface: R primarily uses command-line interface, although graphical user interfaces (GUIs) available, RStudio, provide user-friendly environment coding data analysis.Community Support: R large active community users developers provide support, share code tutorials, contribute ongoing development language.Community Support: R large active community users developers provide support, share code tutorials, contribute ongoing development language.R versatile tool used various fields, including academia, industry, finance, healthcare, , tasks statistical analysis, data visualization, predictive modeling. popularity continues grow data-driven decision-making becomes increasingly important many domains.","code":""},{"path":"part-i-introduction-to-r.html","id":"installing-r-and-rstudio","chapter":"Part I: Introduction to R","heading":"Installing R and Rstudio","text":"Find installation guide pdf file.\nAlternatively , can look videos .Installation R windows Roger PengInstallation R Mac Roger PengHow install Rstudio MacHow install Rstudio Windows","code":""},{"path":"part-i-introduction-to-r.html","id":"basic-rstudio-layout-and-functionality","chapter":"Part I: Introduction to R","heading":"Basic RStudio layout and functionality","text":"\nFigure 1: : http://www.sthda.com/english/wiki/r-basics-quick--easy\nCode Editor/ R script: can write either R code , Rmarkdown. can include instructions computer execute.Code Editor/ R script: can write either R code , Rmarkdown. can include instructions computer execute.R console : see output code run , write code , automatically run enter traced back, R Script useful reusable code.R console : see output code run , write code , automatically run enter traced back, R Script useful reusable code.Workspace history:  space display variables created , use, history , building , git . check data loaded correctly can check see loaded.Workspace history:  space display variables created , use, history , building , git . check data loaded correctly can check see loaded.Plots files:  display graphs plots created, can switch back forth , export, save . Also, can select packages, get help R functions .Plots files:  display graphs plots created, can switch back forth , export, save . Also, can select packages, get help R functions .","code":""},{"path":"part-i-introduction-to-r.html","id":"what-are-packages","chapter":"Part I: Introduction to R","heading":"What are packages?","text":"power R lies packages. Since R open source, many people create packages .e, R scripts contain functions specific problems , may standard deviation , statistics, machine learning .install package, simply typeinstall.packages(\"package name\")Install package Bioconductor: biocLite()Install package Bioconductor: biocLite()Install package GitHub: devtools::install_github()Install package GitHub: devtools::install_github()View list installed packages: installed.packages()View list installed packages: installed.packages()Folder containing installed packages: .libPaths()Folder containing installed packages: .libPaths()load packageTo load packagelibrary(package name)View loaded packagessearch()Unload R package:detach(package name, unload = TRUE)Remove installed packages:remove.packages()Update installed packages:update.packages()","code":""},{"path":"part-ii-r-fundamentals.html","id":"part-ii-r-fundamentals","chapter":"Part II: R Fundamentals","heading":"Part II: R Fundamentals","text":"starting, Official manuals books learning :https://cran.r-project.org/doc/manuals/r-release/R-intro.htmlhttps://cran.r-project.org/doc/manuals/r-release/R-data.htmlhttps://cran.r-project.org/doc/manuals/r-release/R-exts.htmlhttps://cran.r-project.org/doc/manuals/r-release/R-lang.htmlR programming Data Science Roger D. Peng.R Data ScienceIntro R bookR workshopIntro R","code":""},{"path":"part-ii-r-fundamentals.html","id":"r-as-a-calculator","chapter":"Part II: R Fundamentals","heading":"R as a calculator","text":"best way get used R use calculator.can start using R console simple operations.","code":""},{"path":"part-ii-r-fundamentals.html","id":"basic-arithmetic-operations","chapter":"Part II: R Fundamentals","heading":"Basic arithmetic operations","text":"AdditionSubtractionMultiplicationDivisionExponientiation","code":"\n3+5\n#> [1] 8\n143-12\n#> [1] 131\n4*5\n#> [1] 20\n180/23\n#> [1] 7.826087\n4^2\n#> [1] 16"},{"path":"part-ii-r-fundamentals.html","id":"arithmetic-functions","chapter":"Part II: R Fundamentals","heading":"Arithmetic Functions","text":"functions may useful replace calculatorAbsolute valueSquare rootRemainder/moduloLogarithms exponentials\n.e,\\[\\log_a b = c,\\quad ln_e b=, \\quad  e^{}=b\\]","code":"\nabs(-23)\n#> [1] 23\nsqrt(16)\n#> [1] 4\n7 %% 3\n#> [1] 1\nlog2(4)\n#> [1] 2\nlog10(1000)\n#> [1] 3\nlog(4)\n#> [1] 1.386294\nexp(8)\n#> [1] 2980.958\n2.71828^8\n#> [1] 2980.942"},{"path":"part-ii-r-fundamentals.html","id":"variables-and-data-types-numericcharacter","chapter":"Part II: R Fundamentals","heading":"Variables and data types (numeric,character)","text":"","code":""},{"path":"part-ii-r-fundamentals.html","id":"assigment-operators","chapter":"Part II: R Fundamentals","heading":"Assigment Operators","text":"R, create variable , can use assigment symbol <-, = however, later commonly used R.assign value 7 x , doWe can now perform operations variablesRemark: R case sensitive , x different Xcalling print(X) output error","code":"\nx <- 7\nprint(x)\n#> [1] 7\n3*x+3 # 3*7+3 = 21+3 =24\n#> [1] 24\nprint(X)\n#> Error in eval(expr, envir, enclos): object 'X' not found"},{"path":"part-ii-r-fundamentals.html","id":"data-types","chapter":"Part II: R Fundamentals","heading":"Data types","text":"R five basic “atomic” classes objects:characternumeric (real numbers)integercomplexlogical (True/False)","code":""},{"path":"part-ii-r-fundamentals.html","id":"exercise-1","chapter":"Part II: R Fundamentals","heading":"Exercise 1","text":"Run following code, use typeof(), class() functions find data type /class object.Use typeof() class()function find data type variable .","code":"\nmy_numeric <- 42.5\nJohn_jay <- \"university\"\nmy_logical <- TRUE\nmy_date <- as.Date(\"05/29/2018\", \"%m/%d/%Y\")"},{"path":"part-ii-r-fundamentals.html","id":"what-is-the-difference-between-typeof-and-class","chapter":"Part II: R Fundamentals","heading":"What is the difference between typeof() and class()?","text":"can see typeof(my_date) double, class(my_date) Date. typeof output lowest level data type object. class outputs class object.writing code involves checking whether element specific data type , need careful check . Depending function , may give true value reality want false value returned.example, Imagine asked check dates dateframe correct data type.cases might \"05/29/2018\" rare case (maybe due data entry error), \"42.5\"previous comparison , returns true, meaning two data types , maybe youu thought comparing date type, reality , comparing lowest level data types indeed equal (double)Instead, .Character Data type \ncharacter stores character values stringsNumeric Data type numerical values .Integer Data typeFor integers, must specify , , must convert data type. Remark: decimal, remove decimal, acting floor function .can also create integer adding L itRemark: work decimalsComplex Data type\nComplex data types stored x+yi , .e, imaginary componentBoolean Data type \nstores boolean values TRUE FALSE","code":"\ntypeof(my_date) == typeof(my_numeric)\n#> [1] TRUE\nclass(my_date) == class(my_numeric)\n#> [1] FALSE\nchar <- \"This is a character data type\"\nchar\n#> [1] \"This is a character data type\"\ntypeof(char)\n#> [1] \"character\"\nnum <- 3\nprint(num)\n#> [1] 3\nnum_2 <- -2.35\nnum_2\n#> [1] -2.35\ntypeof(num_2)\n#> [1] \"double\"\nclass(num_2)\n#> [1] \"numeric\"\nint <- as.integer(3.6332)\nint\n#> [1] 3\ntypeof(int)\n#> [1] \"integer\"\nint2 <- as.integer(7)\nint2\n#> [1] 7\ntypeof(int2)\n#> [1] \"integer\"\nclass(int2)\n#> [1] \"integer\"\nint3 <- 8L\nint3\n#> [1] 8\nint4 <- 3.4546L\nint4\n#> [1] 3.4546\ncompl <- 13+7i\ncompl\n#> [1] 13+7i\ntypeof(compl)\n#> [1] \"complex\"\ncomplex(real = 23, imaginary = 7)\n#> [1] 23+7i\nmy_bool <- TRUE\nmy_bool\n#> [1] TRUE\n\ntypeof(my_bool)\n#> [1] \"logical\"\n\nmy_boolean <- F\nmy_boolean\n#> [1] FALSE\ntypeof(my_boolean)\n#> [1] \"logical\""},{"path":"part-ii-r-fundamentals.html","id":"what-is-the-difference-between-typeof-and-class-1","chapter":"Part II: R Fundamentals","heading":"2 What is the difference between typeof() and class()?","text":"can see typeof(my_date) double, class(my_date) Date. typeof output lowest level data type object. class outputs class object.writing code involves checking whether element specific data type , need careful check . Depending function , may give true value reality want false value returned.example, Imagine asked check dates dateframe correct data type.cases might \"05/29/2018\" rare case (maybe due data entry error), \"42.5\"previous comparison , returns true, meaning two data types , maybe youu thought comparing date type, reality , comparing lowest level data types indeed equal (double)Instead, .","code":"\ntypeof(my_date) == typeof(my_numeric)\n#> [1] TRUE\nclass(my_date) == class(my_numeric)\n#> [1] FALSE"},{"path":"part-ii-r-fundamentals.html","id":"converting-data-types","chapter":"Part II: R Fundamentals","heading":"Converting Data types","text":"Convert NumericWe can convert values numeric. Using .numeric() change type keeping values .\nconvertingcomplex: removes imaginary partlogical: TRUE becomes 1 , FALSE becomes 0character: numerical values, letters NAWe can use .numeric() check variable numericConvert integerConverting LogicalReturn FALSE 0 , TRUE otherwise","code":"\n# Complex\nis.numeric(compl)\n#> [1] FALSE\nnumber <- as.numeric(compl)\n#> Warning: imaginary parts discarded in coercion\nnumber\n#> [1] 13\nis.numeric(number)\n#> [1] TRUE\n\n#Logical \nis.numeric(my_bool)\n#> [1] FALSE\nnumber2 <- as.numeric(my_bool)\nnumber2\n#> [1] 1\nis.numeric(number2)\n#> [1] TRUE\n\n# Character\nchar\n#> [1] \"This is a character data type\"\nis.numeric(char)\n#> [1] FALSE\nnumber3 <- as.numeric(char)\n#> Warning: NAs introduced by coercion\nnumber3\n#> [1] NA\nis.numeric(number3)\n#> [1] TRUE\n\nmy_char <- \"2023\"\nis.numeric(my_char)\n#> [1] FALSE\nnumber4 <- as.numeric(my_char)\nnumber4\n#> [1] 2023\nis.numeric(number4)\n#> [1] TRUE\ninte1<-as.integer(\"234\")\ninte1\n#> [1] 234\ntypeof(inte1)\n#> [1] \"integer\"\n\ninte2<-as.integer(23+6i)\n#> Warning: imaginary parts discarded in coercion\ninte2\n#> [1] 23\ntypeof(inte2)\n#> [1] \"integer\"\n\ninte3<-as.integer(F)\ninte3\n#> [1] 0\ntypeof(inte3)\n#> [1] \"integer\"\nprint(as.logical(0))\n#> [1] FALSE\ntypeof(as.logical(0))\n#> [1] \"logical\"\n\nprint(as.logical(-324))\n#> [1] TRUE\ntypeof(as.logical(-324))\n#> [1] \"logical\""},{"path":"part-ii-r-fundamentals.html","id":"exercise-2","chapter":"Part II: R Fundamentals","heading":"Exercise 2","text":"Create 1 datatype : Character, numeric, integer, complex, Boolean","code":""},{"path":"part-ii-r-fundamentals.html","id":"getting-help","chapter":"Part II: R Fundamentals","heading":"Getting help","text":"can use Plots files pane (bottom left pane) click Help search whichever function need help .can also use ? function.open information function plots files pane.","code":"\n?mean"},{"path":"part-iii-data-structures.html","id":"part-iii-data-structures","chapter":"Part III: Data Structures","heading":"Part III: Data Structures","text":"","code":""},{"path":"part-iii-data-structures.html","id":"vectors-creating-indexing-and-operations","chapter":"Part III: Data Structures","heading":"Vectors: Creating, indexing, and operations","text":"can give names columns vector","code":"\n# Creating a vector\nv <- c(1, 2, 3, 4, 5)\nprint(v)\n#> [1] 1 2 3 4 5\n\n# Indexing a vector\nprint(v[2])  # Access the second element\n#> [1] 2\n\n# Vector operations\nv2 <- v * 2  # Multiply each element by 2\nprint(v2)\n#> [1]  2  4  6  8 10\nmy_vector <- c(\"Katrien Antonio\", \"teacher\")\nnames(my_vector) <- c(\"Name\", \"Profession\")\nmy_vector\n#>              Name        Profession \n#> \"Katrien Antonio\"         \"teacher\""},{"path":"part-iii-data-structures.html","id":"exercise-1-1","chapter":"Part III: Data Structures","heading":"Exercise 1:","text":"Create vector favorite numbers.Access third element vector.Create new vector square element original vector.Inspect my_vector using:\nattributes(), length() str() function","code":"\nmy_vector <- c(\"Katrien Antonio\", \"teacher\")\nnames(my_vector) <- c(\"Name\", \"Profession\")\nmy_vector\n#>              Name        Profession \n#> \"Katrien Antonio\"         \"teacher\""},{"path":"part-iii-data-structures.html","id":"matrices","chapter":"Part III: Data Structures","heading":"Matrices","text":"Matrices vectors dimension attribute. dimension attribute integer vector length 2 (number rows, number columns)Matrices constructed column-wise, entries can thought starting “upper left” corner running columns.Another exampleMatrices can created column-binding row-binding cbind() rbind() functions.","code":"\nm <- matrix(1:6, nrow = 2, ncol = 3) \nm\n#>      [,1] [,2] [,3]\n#> [1,]    1    3    5\n#> [2,]    2    4    6\nmy_matrix <- matrix(1:12, 3, 4, byrow = TRUE)\nmy_matrix\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\nx <- 1:3\ny <- 10:12\ncbind(x, y)\n#>      x  y\n#> [1,] 1 10\n#> [2,] 2 11\n#> [3,] 3 12\nrbind(x, y)\n#>   [,1] [,2] [,3]\n#> x    1    2    3\n#> y   10   11   12"},{"path":"part-iii-data-structures.html","id":"lists","chapter":"Part III: Data Structures","heading":"Lists","text":"Lists special type vector can contain elements different classes. Lists important data type R get know well. Lists, combination various “apply” functions discussed later, make powerful combination.Lists can explicitly created using list() function, takes arbitrary number arguments.","code":"\nx <- list(1, \"a\", TRUE, 1 + 4i) \nx\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] \"a\"\n#> \n#> [[3]]\n#> [1] TRUE\n#> \n#> [[4]]\n#> [1] 1+4i"},{"path":"part-iii-data-structures.html","id":"example","chapter":"Part III: Data Structures","heading":"Example","text":"","code":"\nmy_list <- list(one = 1, two = c(1, 2), five = seq(1, 4, length=5),\n          six = c(\"Katrien\", \"Jan\"))\nnames(my_list)\n#> [1] \"one\"  \"two\"  \"five\" \"six\"\nstr(my_list)\n#> List of 4\n#>  $ one : num 1\n#>  $ two : num [1:2] 1 2\n#>  $ five: num [1:5] 1 1.75 2.5 3.25 4\n#>  $ six : chr [1:2] \"Katrien\" \"Jan\""},{"path":"part-iii-data-structures.html","id":"factors","chapter":"Part III: Data Structures","heading":"Factors","text":"Factors used represent categorical data can unordered ordered. One can think factor integer vector integer label. Factors important statistical modeling treated specially modelling functions like lm() glm().Using factors labels better using integers factors self-describing. variable values “Male” “Female” better variable values 1 2.Factor objects can created factor() function.Level put alphabetical order, can also define levels.","code":"\nx <- factor(c(\"yes\", \"yes\", \"no\", \"yes\", \"no\")) \nx\n#> [1] yes yes no  yes no \n#> Levels: no yes\nx <- factor(c(\"yes\", \"yes\", \"no\", \"yes\", \"no\"),levels = c(\"yes\", \"no\"))\nx\n#> [1] yes yes no  yes no \n#> Levels: yes no"},{"path":"part-iii-data-structures.html","id":"data-frames-creating-and-exploring-data-frames","chapter":"Part III: Data Structures","heading":"Data frames: Creating and exploring data frames","text":"Data frames used store tabular data R.Data frames represented special type list every element list length. element list can thought column length element list number rows.","code":"\n# Creating a data frame\ndf <- data.frame(\n  Name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  Age = c(25, 30, 35),\n  Salary = c(50000, 60000, 70000)\n)\nprint(df)\n#>      Name Age Salary\n#> 1   Alice  25  50000\n#> 2     Bob  30  60000\n#> 3 Charlie  35  70000\n\n# Exploring data frames\nprint(dim(df))  # Dimensions of the data frame\n#> [1] 3 3\nprint(colnames(df))  # Column names\n#> [1] \"Name\"   \"Age\"    \"Salary\"\nprint(summary(df))  # Summary statistics\n#>      Name                Age           Salary     \n#>  Length:3           Min.   :25.0   Min.   :50000  \n#>  Class :character   1st Qu.:27.5   1st Qu.:55000  \n#>  Mode  :character   Median :30.0   Median :60000  \n#>                     Mean   :30.0   Mean   :60000  \n#>                     3rd Qu.:32.5   3rd Qu.:65000  \n#>                     Max.   :35.0   Max.   :70000"},{"path":"part-iii-data-structures.html","id":"exercise-2-1","chapter":"Part III: Data Structures","heading":"Exercise 2","text":"Create data frame least three columns four rows.Print number rows columns data frame.Display summary statistics data frame.","code":""},{"path":"part-iii-data-structures.html","id":"part-2","chapter":"Part III: Data Structures","heading":"Part 2","text":"","code":""},{"path":"part-iii-data-structures.html","id":"exercise-3","chapter":"Part III: Data Structures","heading":"Exercise 3","text":"Inspect built-data frame, inspect mtcars using str(), head()Get summary variable dataframe, use $ extract variable dataframe.Now inspect tibble, inspect diamonds ggplot2 library. Use str(), head(), summary()Can list differences?","code":"\nmtcars\nstr(mtcars)\nhead(mtcars)\nsummary(mtcars$cyl) # use $ to extract variable from a data frame\nlibrary(ggplot2)\nhead(diamonds)"},{"path":"part-iii-data-structures.html","id":"exercise-4","chapter":"Part III: Data Structures","heading":"Exercise 4","text":"Create vector fav_music names favorite artists.Create vector num_records number records \ncollection artists.Create vector num_concerts number times attended concert artists.Put everything together data frame, assign name my_music data frame change labels information stored columns artist, records concerts.Extract variable num_records data frame my_music.Calculate total number records collection (defined\nset artists).Check structure data frame, ask summary.","code":""},{"path":"part-iii-data-structures.html","id":"importing-and-exporting-data-csv-files","chapter":"Part III: Data Structures","heading":"Importing and exporting data (CSV files)","text":"Exporting data CSVImporting data CSVPreviously, exported data imported . may think, purpose already dataframe. prior just example, reality , dataframe loaded R . csv data file coworker shared data engineer procured .First, need obtain data need. , please head tohttps://tinyurl.com/JJAY-R-workshopalternatively,https://drive.google.com/drive/folders/18W5f2AvKT7IVKnJ73McCzQOOqMdP0CwM?usp=sharingDownload data, , click arrow folder, choose download. Find located computer, obtain PathSome useful instructions regarding path names: get working directoryGet working directoryspecify path name, forward slash double back slashuse relative path","code":"\nwrite.csv(df, \"my_data.csv\", row.names = FALSE)\ndf_imported <- read.csv(\"my_data.csv\")\nprint(df_imported)\n#>      Name Age Salary\n#> 1   Alice  25  50000\n#> 2     Bob  30  60000\n#> 3 Charlie  35  70000\ngetwd()\n#> [1] \"/Users/dilancaro/Library/Mobile Documents/com~apple~CloudDocs/Workshops/John Jay/R Workshop/R-workshop-John-Jay\"\npath <- file.path(\"/Users/dilancaro/Library/Mobile Documents/com~apple~CloudDocs/Workshops/John Jay/R Workshop/R-workshop-John-Jay/John Jay Workshop Data\")\npath <- file.path(\"./John Jay Workshop Data\")"},{"path":"part-iii-data-structures.html","id":"importing-a-.txt-file","chapter":"Part III: Data Structures","heading":"Importing a .txt file","text":"read.table() one great way import data.like thisWhat happened?","code":"\n\npath.hotdogs <- file.path(path, \"hotdogs.txt\")\npath.hotdogs    # inspect path name\n#> [1] \"./John Jay Workshop Data/hotdogs.txt\"\nhotdogs <- read.table(path.hotdogs, header = FALSE,\n                      col.names = c(\"type\", \"calories\", \"sodium\"))\nstr(hotdogs)    # inspect data imported\n#> 'data.frame':    54 obs. of  3 variables:\n#>  $ type    : chr  \"Beef\" \"Beef\" \"Beef\" \"Beef\" ...\n#>  $ calories: int  186 181 176 149 184 190 158 139 175 148 ...\n#>  $ sodium  : int  495 477 425 322 482 587 370 322 479 375 ...\nhotdogs2 <- read.table(path.hotdogs, header = FALSE,\n                       col.names = c(\"type\", \"calories\", \"sodium\"),\n                       colClasses = c(\"factor\", \"NULL\", \"numeric\"))\nstr(hotdogs2)\n#> 'data.frame':    54 obs. of  2 variables:\n#>  $ type  : Factor w/ 3 levels \"Beef\",\"Meat\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ sodium: num  495 477 425 322 482 587 370 322 479 375 ..."},{"path":"part-iii-data-structures.html","id":"import-.csv-file","chapter":"Part III: Data Structures","heading":"Import .csv file","text":"read.csv() another importing function.example:\n- load data set swimming pools Brisbane\n- column names first row; comma separate values within rows","code":"\npath.pools <- file.path(path, \"swimming_pools.csv\")\npools <- read.csv(path.pools)\nstr(pools)\n#> 'data.frame':    20 obs. of  4 variables:\n#>  $ Name     : chr  \"Acacia Ridge Leisure Centre\" \"Bellbowrie Pool\" \"Carole Park\" \"Centenary Pool (inner City)\" ...\n#>  $ Address  : chr  \"1391 Beaudesert Road, Acacia Ridge\" \"Sugarwood Street, Bellbowrie\" \"Cnr Boundary Road and Waterford Road Wacol\" \"400 Gregory Terrace, Spring Hill\" ...\n#>  $ Latitude : num  -27.6 -27.6 -27.6 -27.5 -27.4 ...\n#>  $ Longitude: num  153 153 153 153 153 ..."},{"path":"part-iii-data-structures.html","id":"import-.xlsx-file","chapter":"Part III: Data Structures","heading":"Import .xlsx file","text":"package read excel data R readxl:external dependencies, easy downloadDesgined work tabular dataSpecify worksheet name number, e.g.inspect re-combine","code":"\nlibrary(readxl)\npath.urbanpop <- file.path(path, \"urbanpop.xlsx\")\nexcel_sheets(path.urbanpop) # list sheet names with excel_sheets()\n#> [1] \"1960-1966\" \"1967-1974\" \"1975-2011\"\npop_1 <- read_excel(path.urbanpop, sheet = 1)\npop_2 <- read_excel(path.urbanpop, sheet = 2)\nstr(pop_1)\n#> tibble [209 × 8] (S3: tbl_df/tbl/data.frame)\n#>  $ country: chr [1:209] \"Afghanistan\" \"Albania\" \"Algeria\" \"American Samoa\" ...\n#>  $ 1960   : num [1:209] 769308 494443 3293999 NA NA ...\n#>  $ 1961   : num [1:209] 814923 511803 3515148 13660 8724 ...\n#>  $ 1962   : num [1:209] 858522 529439 3739963 14166 9700 ...\n#>  $ 1963   : num [1:209] 903914 547377 3973289 14759 10748 ...\n#>  $ 1964   : num [1:209] 951226 565572 4220987 15396 11866 ...\n#>  $ 1965   : num [1:209] 1000582 583983 4488176 16045 13053 ...\n#>  $ 1966   : num [1:209] 1058743 602512 4649105 16693 14217 ...\npop_list <- list(pop_1, pop_2)"},{"path":"part-iii-data-structures.html","id":"import-other-data-formats","chapter":"Part III: Data Structures","heading":"Import other data formats","text":"haven package enables R read write various data formats used statistical packages.supports:SAS: read_sas() reads .sas7bdat .sas7bcat files read_xpt() reads SAS transport files. write_sas() writes .sas7bdat files.SPSS: read_sav() reads .sav files read_por() reads older .por files. write_sav() writes .sav files.Stata: read_dta() reads .dta files. write_dta() writes .dta files.","code":""},{"path":"part-iii-data-structures.html","id":"exercise-5","chapter":"Part III: Data Structures","heading":"Exercise 5","text":"Load following data sets, available course material:\n- Danish fire insurance losses, stored danish.txt\n- severity data set, stored severity.sas7bdat.","code":""},{"path":"part-iv-data-manipulation.html","id":"part-iv-data-manipulation","chapter":"Part IV: Data Manipulation","heading":"Part IV: Data Manipulation","text":"","code":""},{"path":"part-iv-data-manipulation.html","id":"subsetting-and-filtering-data","chapter":"Part IV: Data Manipulation","heading":"Subsetting and filtering data","text":"Subsetting filtering data involve selecting specific elements, rows, columns dataset based certain conditions criteria. R, subsetting can achieved using square brackets [], subset() function, dplyr package functions like filter() rows select() columns. Filtering refers specifically choosing rows meet certain conditions, values within range matching specific characteristics.","code":"\n# Creating a sample data frame\ndata <- data.frame(\n  id = 1:5,\n  name = c(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"),\n  age = c(25, 30, 22, 28, 24)\n)\n# Subsetting by a specific column\nages <- data$age\nprint(ages)\n#> [1] 25 30 22 28 24\n\n# Filtering data based on a condition\nyoung_adults <- subset(data, age < 30)\nprint(young_adults)\n#>   id    name age\n#> 1  1   Alice  25\n#> 3  3 Charlie  22\n#> 4  4   David  28\n#> 5  5     Eva  24"},{"path":"part-iv-data-manipulation.html","id":"using-the-dplyr-package","chapter":"Part IV: Data Manipulation","heading":"Using the dplyr package","text":"%>% symbol R known pipe operator, ’s used pass result one expression first argument next expressionFiltering data using dplyr individuals younger 30Subsetting columns using dplyr","code":"\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nyoung_adults <- data %>% filter(age < 30)\nprint(young_adults)\n#>   id    name age\n#> 1  1   Alice  25\n#> 2  3 Charlie  22\n#> 3  4   David  28\n#> 4  5     Eva  24\nages <- data %>% select(age)\nprint(ages)\n#>   age\n#> 1  25\n#> 2  30\n#> 3  22\n#> 4  28\n#> 5  24"},{"path":"part-iv-data-manipulation.html","id":"adding-removing-and-renaming-columns","chapter":"Part IV: Data Manipulation","heading":"Adding, removing, and renaming columns","text":"Adding new column ‘salary’Removing ‘salary’ columnRenaming ‘name’ column ‘first_name’","code":"\ndata$salary <- c(55000, 50000, 60000, 52000, 58000)\nprint(data)\n#>   id    name age salary\n#> 1  1   Alice  25  55000\n#> 2  2     Bob  30  50000\n#> 3  3 Charlie  22  60000\n#> 4  4   David  28  52000\n#> 5  5     Eva  24  58000\ndata$salary <- NULL\nprint(data)\n#>   id    name age\n#> 1  1   Alice  25\n#> 2  2     Bob  30\n#> 3  3 Charlie  22\n#> 4  4   David  28\n#> 5  5     Eva  24\nnames(data)[names(data) == \"name\"] <- \"first_name\"\nprint(data)\n#>   id first_name age\n#> 1  1      Alice  25\n#> 2  2        Bob  30\n#> 3  3    Charlie  22\n#> 4  4      David  28\n#> 5  5        Eva  24"},{"path":"part-iv-data-manipulation.html","id":"using-the-dplyr-package-1","chapter":"Part IV: Data Manipulation","heading":"Using the dplyr package","text":"Adding new column ‘salary’ using mutateRemoving ‘salary’ column using selectRenaming ‘name’ column ‘first_name’ using rename","code":"\ndata <- data %>%\n  mutate(salary = c(55000, 50000, 60000, 52000, 58000))\nprint(data)\n#>   id    name age salary\n#> 1  1   Alice  25  55000\n#> 2  2     Bob  30  50000\n#> 3  3 Charlie  22  60000\n#> 4  4   David  28  52000\n#> 5  5     Eva  24  58000\ndata <- data %>%\n  select(-salary)\nprint(data)\n#>   id    name age\n#> 1  1   Alice  25\n#> 2  2     Bob  30\n#> 3  3 Charlie  22\n#> 4  4   David  28\n#> 5  5     Eva  24\ndata <- data %>%\n  rename(first_name = name)\nprint(data)\n#>   id first_name age\n#> 1  1      Alice  25\n#> 2  2        Bob  30\n#> 3  3    Charlie  22\n#> 4  4      David  28\n#> 5  5        Eva  24"},{"path":"part-iv-data-manipulation.html","id":"why-use-dyplr","chapter":"Part IV: Data Manipulation","heading":"Why use dyplr","text":"One might think using pipe operator (%>%) magrittr package, prominently used dplyr wider tidyverse unnecessarily complex. may seem complex first, especially accustomed base R functions syntax, offers several benefits can greatly enhance readability, efficiency, overall workflow data analysis. reasons use :Improved Readability ClarityEasier Debugging ModificationEnhanced WorkflowConsistency Community AdoptionEfficiency Writing CodeAn example benefits seen complex operations making readableLet’s just add salary column .Now, using dplyr","code":"\ndata$salary <- c(55000, 50000, 60000, 52000, 58000)\nsubsetting_data <- rename(select(\n                          filter(data, age < 30), -salary),\n                          first_name = name)\nsubsetting_data\n#>   id first_name age\n#> 1  1      Alice  25\n#> 2  3    Charlie  22\n#> 3  4      David  28\n#> 4  5        Eva  24\n\ndata <- data %>%\n  mutate(salary = c(55000, 50000, 60000, 52000, 58000))\n\ndata <- data %>%\n  filter(age < 30) %>%\n  select(-salary) %>%\n  rename(first_name = name)\ndata\n#>   id first_name age\n#> 1  1      Alice  25\n#> 2  3    Charlie  22\n#> 3  4      David  28\n#> 4  5        Eva  24"},{"path":"part-iv-data-manipulation.html","id":"basic-data-summary-and-exploration","chapter":"Part IV: Data Manipulation","heading":"Basic data summary and exploration","text":"brief summary data exploration given .Summary statistics data frameStructure data frameAverage age individuals data frameCount unique names data frame","code":"\nsummary(data)\n#>        id        first_name             age       \n#>  Min.   :1.00   Length:4           Min.   :22.00  \n#>  1st Qu.:2.50   Class :character   1st Qu.:23.50  \n#>  Median :3.50   Mode  :character   Median :24.50  \n#>  Mean   :3.25                      Mean   :24.75  \n#>  3rd Qu.:4.25                      3rd Qu.:25.75  \n#>  Max.   :5.00                      Max.   :28.00\nstr(data)\n#> 'data.frame':    4 obs. of  3 variables:\n#>  $ id        : int  1 3 4 5\n#>  $ first_name: chr  \"Alice\" \"Charlie\" \"David\" \"Eva\"\n#>  $ age       : num  25 22 28 24\naverage_age <- mean(data$age)\nprint(average_age)\n#> [1] 24.75\nunique_names_count <- length(unique(data$first_name))\nprint(unique_names_count)\n#> [1] 4"},{"path":"part-iv-data-manipulation.html","id":"exploratory-data-analysis","chapter":"Part IV: Data Manipulation","heading":"Exploratory data analysis","text":"Exploratory Data Analysis (EDA) critical initial step data analysis process, main characteristics dataset examined understand structure, uncover patterns, identify anomalies, test hypotheses. goal use statistical summaries visualizations get sense data, guides analysis modeling decisions. EDA making formal predictions testing hypotheses rather asking questions seeking insights open-ended, exploratory manner.Key Components EDA include:Understanding Distribution various variables dataset. involves looking measures like mean, median, mode, range, variance, standard deviation, using visual tools like histograms, box plots, density plots understand data spread .Understanding Distribution various variables dataset. involves looking measures like mean, median, mode, range, variance, standard deviation, using visual tools like histograms, box plots, density plots understand data spread .Identifying Patterns Relationships variables using scatter plots, pair plots, correlation matrices. helps understanding variables related can guide complex analyses like regression classification.Identifying Patterns Relationships variables using scatter plots, pair plots, correlation matrices. helps understanding variables related can guide complex analyses like regression classification.Detecting Anomalies outliers unexpected values might indicate errors data collection provide insights unusual occurrences data.Detecting Anomalies outliers unexpected values might indicate errors data collection provide insights unusual occurrences data.Cleaning Data addressing missing values, duplicate data, making decisions correct inconsistencies based insights gained.Cleaning Data addressing missing values, duplicate data, making decisions correct inconsistencies based insights gained.Transforming Variables necessary make data suitable analysis. involve normalizing data, creating categorical variables continuous ones, engineering new variables existing ones.Transforming Variables necessary make data suitable analysis. involve normalizing data, creating categorical variables continuous ones, engineering new variables existing ones.Tools TechniquesStatistical Summary Functions R (summary(), mean(), sd(), etc.) provide quick insights basic properties data.Visualization Libraries like ggplot2 R creating wide range plots charts reveal underlying patterns structures data.Importance EDAData Understanding: ensures analyst thorough understanding dataset’s features, values, relationships variables.Data Understanding: ensures analyst thorough understanding dataset’s features, values, relationships variables.Guiding Hypotheses: Insights gained EDA can help form hypotheses statistical testing predictive modeling.Guiding Hypotheses: Insights gained EDA can help form hypotheses statistical testing predictive modeling.Modeling Strategy: Identifying key variables relationships helps choosing appropriate models techniques analysis.Modeling Strategy: Identifying key variables relationships helps choosing appropriate models techniques analysis.summary, EDA essential practice data science making sense data, discovering patterns, identifying potential problems, informing subsequent steps analytical process. blends statistical techniques visual explorations create foundation data-driven task.Now explore dataset library AER , numeric variable first","code":""},{"path":"part-iv-data-manipulation.html","id":"numeric-variable","chapter":"Part IV: Data Manipulation","heading":"Numeric Variable","text":"Obtain summary statistics data frame, check whether numeric, get mean , variance.Now, visualize wage distribution","code":"\n#install.packages(\"AER\")\nlibrary(AER)\n#> Loading required package: car\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\n#> Loading required package: lmtest\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> Loading required package: sandwich\n#> Loading required package: survival\ndata(\"CPS1985\")\nstr(CPS1985)\n#> 'data.frame':    534 obs. of  11 variables:\n#>  $ wage      : num  5.1 4.95 6.67 4 7.5 ...\n#>  $ education : num  8 9 12 12 12 13 10 12 16 12 ...\n#>  $ experience: num  21 42 1 4 17 9 27 9 11 9 ...\n#>  $ age       : num  35 57 19 22 35 28 43 27 33 27 ...\n#>  $ ethnicity : Factor w/ 3 levels \"cauc\",\"hispanic\",..: 2 1 1 1 1 1 1 1 1 1 ...\n#>  $ region    : Factor w/ 2 levels \"south\",\"other\": 2 2 2 2 2 2 1 2 2 2 ...\n#>  $ gender    : Factor w/ 2 levels \"male\",\"female\": 2 2 1 1 1 1 1 1 1 1 ...\n#>  $ occupation: Factor w/ 6 levels \"worker\",\"technical\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#>  $ sector    : Factor w/ 3 levels \"manufacturing\",..: 1 1 1 3 3 3 3 3 1 3 ...\n#>  $ union     : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 2 1 1 1 1 ...\n#>  $ married   : Factor w/ 2 levels \"no\",\"yes\": 2 2 1 1 2 1 1 1 2 1 ...\nhead(CPS1985)\n#>       wage education experience age ethnicity region gender\n#> 1     5.10         8         21  35  hispanic  other female\n#> 1100  4.95         9         42  57      cauc  other female\n#> 2     6.67        12          1  19      cauc  other   male\n#> 3     4.00        12          4  22      cauc  other   male\n#> 4     7.50        12         17  35      cauc  other   male\n#> 5    13.07        13          9  28      cauc  other   male\n#>      occupation        sector union married\n#> 1        worker manufacturing    no     yes\n#> 1100     worker manufacturing    no     yes\n#> 2        worker manufacturing    no      no\n#> 3        worker         other    no      no\n#> 4        worker         other    no     yes\n#> 5        worker         other   yes      no\nsummary(CPS1985$wage)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>   1.000   5.250   7.780   9.024  11.250  44.500\nis.numeric(CPS1985$wage)\n#> [1] TRUE\nmean(CPS1985$wage)\n#> [1] 9.024064\nvar(CPS1985$wage)\n#> [1] 26.41032\nhist(log(CPS1985$wage), freq = FALSE, nclass = 20, col = \"light blue\")\nlines(density(log(CPS1985$wage)), col = \"red\")"},{"path":"part-iv-data-manipulation.html","id":"a-factor-variable","chapter":"Part IV: Data Manipulation","heading":"A factor variable","text":"now explore occupation variablechange names levelsvisualize distribution","code":"\nsummary(CPS1985$occupation)\n#>     worker  technical   services     office      sales \n#>        156        105         83         97         38 \n#> management \n#>         55\nlevels(CPS1985$occupation)[c(2, 6)] <- c(\"techn\", \"mgmt\")\nsummary(CPS1985$occupation)\n#>   worker    techn services   office    sales     mgmt \n#>      156      105       83       97       38       55\ntab <- table(CPS1985$occupation)\nprop.table(tab)\n#> \n#>     worker      techn   services     office      sales \n#> 0.29213483 0.19662921 0.15543071 0.18164794 0.07116105 \n#>       mgmt \n#> 0.10299625\nbarplot(tab)\npie(tab, col = gray(seq(0.4, 1.0, length = 6)))"},{"path":"part-iv-data-manipulation.html","id":"two-factor-variables","chapter":"Part IV: Data Manipulation","heading":"Two factor variables","text":"now explore factor variables gender occupation.Use prop.table()prop.table() function R used compute proportion table elements margin specified (). applied contingency table created table() function, transforms table’s counts proportions, making easier analyze relative distribution frequencies across different categories.Now try prop.table(table(gender, occupation), 2)now explore factor variables gender occupation.mosaic plotA mosaic plot, also known Marimekko diagram mosaic chart, graphical representation data allows visualization proportions frequencies categorical variables dataset. ’s type plot provides visual summary contingency table associated two categorical variables. rectangle (tile) mosaic plot represents combination category levels variables, area rectangle proportional frequency proportion observations category combination.Now explore factor gender numeric variable wage.tapply() function R used apply function subsets vector, subsets defined vector, usually factor. basic syntax tapply() :X object split operated .INDEX factor list factors according X split.FUN function applied subset X.… optional arguments FUN.simplify, TRUE, tries simplify result vector, matrix, higher-dimensional array; FALSE, result list.","code":"\nattach(CPS1985) # attach the data set to avoid use the operator $\ntable(gender, occupation) # no name_df$name_var necessary\n#>         occupation\n#> gender   worker techn services office sales mgmt\n#>   male      126    53       34     21    21   34\n#>   female     30    52       49     76    17   21\nprop.table(table(gender, occupation))\n#>         occupation\n#> gender       worker      techn   services     office\n#>   male   0.23595506 0.09925094 0.06367041 0.03932584\n#>   female 0.05617978 0.09737828 0.09176030 0.14232210\n#>         occupation\n#> gender        sales       mgmt\n#>   male   0.03932584 0.06367041\n#>   female 0.03183521 0.03932584\nprop.table(table(gender, occupation), 2) # 1 for row , 2 for columns\n#>         occupation\n#> gender      worker     techn  services    office     sales\n#>   male   0.8076923 0.5047619 0.4096386 0.2164948 0.5526316\n#>   female 0.1923077 0.4952381 0.5903614 0.7835052 0.4473684\n#>         occupation\n#> gender        mgmt\n#>   male   0.6181818\n#>   female 0.3818182\nplot(gender ~ occupation, data = CPS1985)\ntapply(wage, gender, mean)\n#>     male   female \n#> 9.994913 7.878857\ntapply(log(wage), list(gender, occupation), mean)\n#>          worker    techn services   office    sales\n#> male   2.100418 2.446640 1.829568 1.955284 2.141071\n#> female 1.667887 2.307509 1.701674 1.931128 1.579409\n#>            mgmt\n#> male   2.447476\n#> female 2.229256"},{"path":"part-iv-data-manipulation.html","id":"a-factor-and-a-numeric-variable","chapter":"Part IV: Data Manipulation","heading":"A factor and a numeric variable","text":"Explore factor variable numeric variable.\nVisualize distribution wage per genderNow try ","code":"\nboxplot(log(wage) ~ gender, data = CPS1985)\nboxplot(log(wage) ~ gender + occupation, data = CPS1985)\ndetach(CPS1985) # now detach when work is done"},{"path":"part-v-basic-data-visualization.html","id":"part-v-basic-data-visualization","chapter":"Part V: Basic Data Visualization","heading":"Part V: Basic Data Visualization","text":"","code":""},{"path":"part-v-basic-data-visualization.html","id":"creating-simple-plots-using-plot-hist-piebarplotboxplot","chapter":"Part V: Basic Data Visualization","heading":"Creating simple plots using plot(), hist(), pie(),barplot(),boxplot()","text":"R, plot() function generic function used making variety graphs. simplest, used create scatter plots can customized create line plots, add model lines, much .","code":""},{"path":"part-v-basic-data-visualization.html","id":"basic-arguments","chapter":"Part V: Basic Data Visualization","heading":"Basic Arguments:","text":"x: coordinates points plot. simple scatter plot, typically numeric vector.y: coordinates points plot y-axis. length x.type: type plot drawn. Possible types include “p” points (default), “l” lines, “b” , several others.main: main title plot.xlab: label x-axis.ylab: label y-axis.xlim: Limits x-axis.ylim: Limits y-axis.pch: Plotting character, symbol use plot. Different numbers correspond different symbols.col: Color points. Can also vector color points differently based factor.","code":""},{"path":"part-v-basic-data-visualization.html","id":"additional-customizations","chapter":"Part V: Basic Data Visualization","heading":"Additional Customizations:","text":"cex: numerical value giving amount plotting text symbols magnified relative default.lwd: Line width plot, useful plot type includes lines.bg: Background color open plot symbols specified pch.\nAdvanced Features:abline: function add straight lines plot, either vertical, horizontal, regression lines.lines: function add lines plot, context existing plot; doesn’t start new plot.\npoints: Add points plot.","code":""},{"path":"part-v-basic-data-visualization.html","id":"adding-a-legend","chapter":"Part V: Basic Data Visualization","heading":"Adding a Legend:","text":"add legend, use legend() function. provides number arguments customize appearance:legend: vector text values expression describing text appear legend.\nx, y position: location legend. x y can numeric positions, can use keyword positions like \"topright\", \"bottomleft\", \"bottomright\" , \"bottom\", \"bottomleft\", \"left\", \"topleft\", \"top\", \"right\", \"center\".\npch: plotting symbols points appearing legend, matching plot.\ncol: colors points lines appearing legend, matching plot.\nlwd: line widths lines appearing legend, matching plot.\ncex: Character expansion size legend, determining large text legend .","code":""},{"path":"part-v-basic-data-visualization.html","id":"example-1-simple-scatter-plot","chapter":"Part V: Basic Data Visualization","heading":"Example 1 : Simple scatter plot","text":"","code":"\n\nx <- 1:10\ny <- rnorm(10)\nplot(x, y, main = \"Simple Scatter Plot\", xlab = \"X Axis\", ylab = \"Y Axis\", col = \"blue\")"},{"path":"part-v-basic-data-visualization.html","id":"exercise-1-2","chapter":"Part V: Basic Data Visualization","heading":"Exercise 1","text":"Making Scatter plot:load journals.txt data set save Journals data frameWork following instructionsNow adjust plotting instructionsThe curve() function draws curve corresponding function interval [, ].","code":"\nplot(log(Journals$subs), log(Journals$price))\nrug(log(Journals$subs))\nrug(log(Journals$price), side = 2)\nplot(log(Journals$price) ~ log(Journals$subs), pch = 19,\n     col = \"blue\", xlim = c(0, 7), ylim = c(3, 8),\n     main = \"Library subscriptions\")\nrug(log(Journals$subs))\nrug(log(Journals$price), side=2)\ncurve(dnorm, from = -5, to = 5, col = \"red\", lwd = 3,\n      main = \"Density of the standard normal distribution\")"},{"path":"part-v-basic-data-visualization.html","id":"example-2","chapter":"Part V: Basic Data Visualization","heading":"Example 2","text":"create basic scatter plot, can use mtcars dataset, comes built R. dataset contains various characteristics 32 automobiles.","code":"\n\ndata(mtcars)\n\n\nplot(mtcars$hp, mtcars$mpg, main=\"MPG vs. Horsepower\",\n     xlab=\"Horsepower\", ylab=\"Miles Per Gallon\",\n     pch=19, col=\"blue\")"},{"path":"part-v-basic-data-visualization.html","id":"example-3","chapter":"Part V: Basic Data Visualization","heading":"Example 3","text":"Using pressure dataset, also built R, can create simple line plot. pressure dataset shows temperature resulting vapor pressure mercury.","code":"\n\ndata(pressure)\n\n# Create a line plot\nplot(pressure$temperature, pressure$pressure, type=\"l\",\n     main=\"Vapor Pressure of Mercury\",\n     xlab=\"Temperature\", ylab=\"Pressure\",\n     col=\"red\", lwd=2)"},{"path":"part-v-basic-data-visualization.html","id":"example-4","chapter":"Part V: Basic Data Visualization","heading":"Example 4","text":"Explanation:iris$Sepal.Length: selects Sepal.Length column iris dataset x-coordinates plot.\niris$Sepal.Width: selects Sepal.Width column iris dataset y-coordinates plot.\ncol=iris$Species: assigns colors points based Species column, means species different color plot.\nmain: Sets title plot “Iris Sepal Measurements”.\nxlab: Sets label x-axis “Sepal Length”.\nylab: Sets label y-axis “Sepal Width”.\npch=19: Sets plotting character (point symbol) solid circle.","code":"\n\ndata(iris)\n\n# Plot Sepal.Length vs. Sepal.Width colored by Species\nplot(iris$Sepal.Length, iris$Sepal.Width, col=iris$Species,\n     main=\"Iris Sepal Measurements\",\n     xlab=\"Sepal Length\", ylab=\"Sepal Width\",\n     pch=19)\nlegend(\"topright\", legend=levels(iris$Species), col=1:3, pch=19)"},{"path":"part-v-basic-data-visualization.html","id":"example-5","chapter":"Part V: Basic Data Visualization","heading":"Example 5","text":"plot() generic function create scatter plot.\nmtcars\\(disp mtcars\\)mpg x y coordinates plot, representing engine displacement cubic inches miles per gallon, respectively.col=.factor(mtcars$cyl) specifies colors points plot. cyl variable, represents number cylinders car’s engine, converted factor. levels factor (unique values cyl) automatically given different colors.main main title plot.xlab ylab labels x-axis y-axis, respectively.pch=19 specifies plotting symbol (case, solid circle).cex=1.5 sets size plot symbols; cex stands character expansion factor, 1.5 means 150% default size.legend,legend() adds legend plot.\"topright\" specifies position legend (case, top right corner plotting area).legend= creates text legend pasting word “Cylinders:” front unique value cyl column. indicates color scatter plot corresponds .col= sets colors used legend, match colors used points plot.pch=19 specifies plotting symbols used legend.cex=0.8 sets size symbols legend.","code":"\n# Load the mtcars dataset\ndata(mtcars)\n\n# Plot MPG vs. Displacement, colored by Cylinders\nplot(mtcars$disp, mtcars$mpg, col=as.factor(mtcars$cyl),\n     main=\"Scatter Plot of MPG vs. Displacement\",\n     xlab=\"Displacement (cu.in.)\", ylab=\"MPG\",\n     pch=19, cex=1.5)\n\n# Add a legend to the plot\nlegend(\"topright\", \n       legend=paste(\"Cylinders:\", unique(mtcars$cyl)), \n       col=unique(as.numeric(as.factor(mtcars$cyl))), \n       pch=19, cex=0.8)"},{"path":"part-v-basic-data-visualization.html","id":"example-6","chapter":"Part V: Basic Data Visualization","heading":"Example 6","text":"","code":""},{"path":"part-v-basic-data-visualization.html","id":"scatterplot","chapter":"Part V: Basic Data Visualization","heading":"Scatterplot()","text":"common high level function used produce plots R (rather unsurprisingly) plot() function. example, let’s plot weight petunia plants flowers data frame flower.xlsUse library readxl, read_excel() function.Alternatively , can also use flower.txt use read_taTo plot scatterplot one numeric variable another numeric variable just need include variables arguments using plot() function. example plot shootarea y axis weight x axis.equivalent approach types plots often causes confusion first. can also use formula notation using plot() function. However, contrast previous method formula method requires specify y axis variable first, ~x axis variable.","code":"\n\nlibrary(readxl)\nflowers <- read_excel('./John Jay Workshop Data/flower.xls')\n\nplot(flowers$weight)\nflowers <- read.table(file = './John Jay Workshop Data/flower.txt', \n                        header = TRUE, sep = \"\\t\", \n                        stringsAsFactors = TRUE)\nplot(x = flowers$weight, y = flowers$shootarea)\nplot(flowers$shootarea ~ flowers$weight)"},{"path":"part-v-basic-data-visualization.html","id":"histogram","chapter":"Part V: Basic Data Visualization","heading":"Histogram","text":"can also display histogram proportion rather frequency using freq = FALSE argument.alternative plotting just straight histogram add kernel density curve plot. can superimpose density curve onto histogram first using density() function compute kernel density estimates use low level function lines() add estimates onto plot line.","code":"\nhist(flowers$height)\nbrk <- seq(from = 0, to = 18, by = 1)\nhist(flowers$height, breaks = brk, main = \"petunia height\")\nbrk <- seq(from = 0, to = 18, by = 1)\nhist(flowers$height, breaks = brk, main = \"petunia height\",\n      freq = FALSE)\ndens <- density(flowers$height)\nhist(flowers$height, breaks = brk, main = \"petunia height\",\n      freq = FALSE)\nlines(dens)"},{"path":"part-v-basic-data-visualization.html","id":"boxplot","chapter":"Part V: Basic Data Visualization","heading":"Boxplot","text":"OK, ’ll just come say , love boxplots close relation violin plot. Boxplots (box--whisker plots give full name) useful want graphically summarise distribution variable, identify potential unusual values compare distributions different groups. reason love ease interpretation, transparency relatively high data--ink ratio (.e. convey lots information efficiently). suggest try use boxplots much possible exploring data avoid temptation use ubiquitous bar plot (even standard error 95% confidence intervals bars). problem bar plots (aka dynamite plots) hide important information reader distribution data assume error bars (confidence intervals) symmetric around mean. course, ’s ’re tempted use bar plots just Google ‘dynamite plots evil’ see hereTo create boxplot R use boxplot() function. example, let’s create boxplot variable weight flowers data frame. can also include y axis label using ylab = argument.want examine distribution variable changes different levels factor need use formula notation boxplot() function. example, let’s plot weight variable , time see changes level nitrogen. use formula notation boxplot() can use data = argument save typing. ’ll also introduce x axis label using xlab = argument.factor levels plotted order defined factor variable nitrogen (often alphabetically). change order need change order levels nitrogen factor data frame using factor() function re-plot graph. Let’s plot boxplot factor levels going low high.can also group variables two factors plot. Let’s plot weight variable time plot separate box nitrogen treatment (treat) combination.plot looks OK, group labels hidden ’re long fit plot. couple ways deal . Perhaps easiest reduce font size tick mark labels plot fit using cex.axis = argument. Let’s set font size 30% smaller default cex.axis = 0.7Violin plots like combination boxplot kernel density plot (saw example kernel density plot histogram section ) rolled one figure. can create violin plot R using vioplot() function vioplot package. ’ll need first install package using install.packages(‘vioplot’) function usual. nice thing vioplot() function use pretty much way use boxplot() function. ’ll also use argument col = “lightblue” change fill colour light blue.","code":"\nboxplot(flowers$weight, ylab = \"weight (g)\")\nboxplot(weight ~ nitrogen, data = flowers, \n         ylab = \"weight (g)\", xlab = \"nitrogen level\")\nflowers$nitrogen <- factor(flowers$nitrogen, \n                            levels = c(\"low\", \"medium\", \"high\"))\nboxplot(weight ~ nitrogen, data = flowers, \n          ylab = \"weight (g)\", xlab = \"nitrogen level\")\nboxplot(weight ~ nitrogen * treat, data = flowers, \n         ylab = \"weight (g)\", xlab = \"nitrogen level\")\nboxplot(weight ~ nitrogen * treat, data = flowers, \n         ylab = \"weight (g)\", xlab = \"nitrogen level\", \n         cex.axis = 0.7)\n#install.packages(\"vioplot\")\nlibrary(vioplot)\n#> Loading required package: sm\n#> Package 'sm', version 2.2-6.0: type help(sm) for summary information\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\nvioplot(weight ~ nitrogen, data = flowers, \n         ylab = \"weight (g)\", xlab = \"nitrogen level\",\n         col = \"lightblue\")"},{"path":"part-v-basic-data-visualization.html","id":"pairs-plot","chapter":"Part V: Basic Data Visualization","heading":"Pairs plot","text":"","code":"\nplot(flowers)\npairs(flowers[, c(\"height\", \"weight\", \"leafarea\", \n                \"shootarea\", \"flowers\")])"},{"path":"part-v-basic-data-visualization.html","id":"exercise-1-3","chapter":"Part V: Basic Data Visualization","heading":"Exercise 1","text":"Now, try creating visualization using iris dataset. ’s can :Create scatter plot using Petal.Length Petal.Width iris dataset.Color points based Species column differentiate species.Add title, x-axis label, y-axis label plot.\nInclude legend indicates color corresponds iris species.","code":""},{"path":"intermediate-r.html","id":"intermediate-r","chapter":"Intermediate R","heading":"Intermediate R","text":"session , learn function control structures writing functions , statements, loops.also explore Data Cleaning Transformations handling missing data , reshaping data using dplyr functions.First , need load packageIt loadggplot2: Used data visualization using grammar graphics.dplyr: Provides set tools efficiently manipulating datasets.tidyr: Used tidying data, , transforming format easy work .readr: Used read rectangular data like CSVs text files R.purrr: Enhances R’s functional programming (FP) toolkit, making easier work lists functions.tibble: modern reimagining data frames, providing cleaner user-friendly data structure.stringr: Simplifies process working strings (text data).forcats: Designed handle categorical variables (factors) ease.session , use ","code":"\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#> ── Attaching core tidyverse packages ──── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#> ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.2     \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"},{"path":"part-i-functions-and-control-structures.html","id":"part-i-functions-and-control-structures","chapter":"Part I: Functions and Control Structures","heading":"Part I: Functions and Control Structures","text":"","code":""},{"path":"part-i-functions-and-control-structures.html","id":"writing-and-using-functions","chapter":"Part I: Functions and Control Structures","heading":"Writing and using functions","text":"Example: simple function calculate square number\\[\nf(x) = x^2\n\\]","code":"\n\nsquare_function <- function(x) {\n  return(x^2)\n}\n\n# Using the function\nresult <- square_function(4)\nprint(result)\n#> [1] 16"},{"path":"part-i-functions-and-control-structures.html","id":"exercise-1-4","chapter":"Part I: Functions and Control Structures","heading":"Exercise 1","text":"Task: Write Use Function\nObjective: Create function calculates cube number use function calculate cube 3.Hint: Use structure square_function template.reason useful, functions used anything want, R functions just similar one just created, optimized specific tasks designed .now create complex function , one takes vector , finds mean , standard deviation histogram","code":"\nanalyze_vector <- function(x, plot_title = \"Histogram\") {\n  # Check if the input is numeric\n  if (!is.numeric(x)) {\n    stop(\"Input must be a numeric vector\")\n  }\n  \n  # Calculate mean and standard deviation\n  mean_value <- mean(x)\n  std_value <- sd(x)\n  \n  # Output the mean and std\n  cat(\"Mean:\", mean_value, \"\\n\")\n  cat(\"Standard Deviation:\", std_value, \"\\n\")\n  \n  # Create a histogram\n  hist(x, main = plot_title, xlab = \"Values\", col = \"lightblue\", border = \"black\")\n  \n  # Return a list containing the mean and std\n  return(list(mean = mean_value, std = std_value))\n}\n\n# Example usage with the mtcars$mpg vector\nresult <- analyze_vector(mtcars$mpg, \"MPG Histogram\")\n#> Mean: 20.09062 \n#> Standard Deviation: 6.026948"},{"path":"part-i-functions-and-control-structures.html","id":"exercise-2-2","chapter":"Part I: Functions and Control Structures","heading":"Exercise 2","text":"Task: Analyze Numeric Vector\nObjective: Write function named summarize_vector takes numeric vector input calculates median, variance, creates boxplot. function print median variance, return list. Use airquality$Ozone data analysis.Hint: Similar analyze_vector, check input numeric use median, var, boxplot functions.","code":""},{"path":"part-i-functions-and-control-structures.html","id":"if-statements-and-loops-for-and-while","chapter":"Part I: Functions and Control Structures","heading":"If statements and loops (for and while)","text":"","code":"\n# Example: Using if statement\nnumber <- 5\nif (number > 0) {\n  print(\"Positive number\")\n} else {\n  print(\"Non-positive number\")\n}\n#> [1] \"Positive number\""},{"path":"part-i-functions-and-control-structures.html","id":"exercise-3-1","chapter":"Part I: Functions and Control Structures","heading":"Exercise 3","text":"Task: Using Statements\nObjective: Create R script checks number negative, zero, positive prints appropriate message. Test script number -4.Hint: Use statement followed else else.","code":""},{"path":"part-i-functions-and-control-structures.html","id":"example-1","chapter":"Part I: Functions and Control Structures","heading":"Example:","text":"loop calculate factorial number","code":"\n\nfactorial_function <- function(n) {\n  result <- 1\n  for (i in 1:n) {\n    result <- result * i\n  }\n  return(result)\n}\n\nfactorial_of_5 <- factorial_function(5)\nprint(factorial_of_5)\n#> [1] 120"},{"path":"part-i-functions-and-control-structures.html","id":"exercise-4-1","chapter":"Part I: Functions and Control Structures","heading":"Exercise 4","text":"Task: Loop\nObjective: Write function using loop calculates sum squares numbers 1 n. Use function calculate sum squares n=10.Hint: Iterate 1 n, keep adding square number result variable.","code":""},{"path":"part-i-functions-and-control-structures.html","id":"example-7","chapter":"Part I: Functions and Control Structures","heading":"Example:","text":"loop find first square number greater 100","code":"\n\nnumber <- 1\nwhile (number^2 <= 100) {\n  number <- number + 1\n}\nprint(paste(\"First square number greater than 100 is:\", number^2))\n#> [1] \"First square number greater than 100 is: 121\""},{"path":"part-i-functions-and-control-structures.html","id":"exercise-5-1","chapter":"Part I: Functions and Control Structures","heading":"Exercise 5","text":"Task: Loop\nObjective: Write script using loop finds smallest number whose cube greater 100. Print number cube.Hint: Increment number starting 1, check cube greater 100 loop condition.","code":""},{"path":"part-ii-data-wrangling.html","id":"part-ii-data-wrangling","chapter":"Part II: Data Wrangling","heading":"Part II: Data Wrangling","text":"Data wrangling, also known data munging, process transforming mapping data one “raw” form another format intent making appropriate valuable variety downstream purposes, analytics.R, data wrangling often performed using functions base R language, well collection packages known tidyverse. tidyverse coherent system packages data manipulation, exploration, visualization share common design philosophy.tidyverse approach data wrangling typically involves:Tidying Data: Transforming datasets consistent form makes easier work . usually means converting data tidy format variable forms column, observation forms row, type observational unit forms table.Tidying Data: Transforming datasets consistent form makes easier work . usually means converting data tidy format variable forms column, observation forms row, type observational unit forms table.Transforming Data: data tidy, series functions used data manipulation tasks selecting specific columns (select()), filtering certain rows (filter()), creating new columns modifying existing ones (mutate() transmute()), summarizing data (summarise()), reshaping data (pivot_longer() pivot_wider()).Transforming Data: data tidy, series functions used data manipulation tasks selecting specific columns (select()), filtering certain rows (filter()), creating new columns modifying existing ones (mutate() transmute()), summarizing data (summarise()), reshaping data (pivot_longer() pivot_wider()).Working Data Types Structures: Functions tidyverse allow easy manipulation data types (like converting character vectors factors forcats) data structures (like tibbles tibble package, modern take data frames).Working Data Types Structures: Functions tidyverse allow easy manipulation data types (like converting character vectors factors forcats) data structures (like tibbles tibble package, modern take data frames).Joining Data: Combining different datasets variety ways (like left_join(), right_join(), inner_join(), full_join(), anti_join()) based common keys identifiers.Joining Data: Combining different datasets variety ways (like left_join(), right_join(), inner_join(), full_join(), anti_join()) based common keys identifiers.Handling Strings Dates: tidyverse includes packages like stringr string operations lubridate dealing date-time objects, essential many data wrangling tasks.Handling Strings Dates: tidyverse includes packages like stringr string operations lubridate dealing date-time objects, essential many data wrangling tasks.Functional Programming: package purrr introduces powerful functional programming tools iterate data structures perform operations repeatedly.Functional Programming: package purrr introduces powerful functional programming tools iterate data structures perform operations repeatedly.primary goal data wrangling ensure data best possible format analysis. tidyverse provides tools make tasks straightforward, efficient, often intuitive base R equivalents. philosophy tidyverse write readable transparent code can understood even come back months years later.","code":""},{"path":"part-ii-data-wrangling.html","id":"reshaping-data-using-dplyr-functions-filter-arrange-mutate-summarize","chapter":"Part II: Data Wrangling","heading":"Reshaping data using dplyr functions (filter, arrange, mutate, summarize)","text":"dplyr package developed Hadley Wickham RStudio optimized distilled version plyr package. dplyr package provide “new” functionality R per se, sense everything dplyr already done base R, greatly simplifies existing functionality R.One important contribution dplyr package provides “grammar” (particular, verbs) data manipulation operating data frames. grammar, can sensibly communicate data frame people can understand (assuming also know grammar). useful provides abstraction data manipulation previously exist. Another useful contribution dplyr functions fast, many key operations coded C++.dplyr grammarSome key “verbs” provided dplyr package areselect: return subset columns data frame, using flexible notationselect: return subset columns data frame, using flexible notationfilter: extract subset rows data frame based logical conditionsfilter: extract subset rows data frame based logical conditionsarrange: reorder rows data framearrange: reorder rows data framerename: rename variables data framerename: rename variables data framemutate: add new variables/columns transform existing variablesmutate: add new variables/columns transform existing variablessummarise / summarize: generate summary statistics different variables data frame, possibly within stratasummarise / summarize: generate summary statistics different variables data frame, possibly within strata%>%: “pipe” operator used connect multiple verb actions together pipeline.%>%: “pipe” operator used connect multiple verb actions together pipeline.combine naturally group_by() allows perform operation “group”.","code":""},{"path":"part-ii-data-wrangling.html","id":"more-on-the-pipe-operator","chapter":"Part II: Data Wrangling","heading":"More on the pipe operator","text":"takes output one statement makes input next statement.describing , can think “”. first example:\ntake diamonds data (ggplot2 package)\nsubset\ntake diamonds data (ggplot2 package)subset","code":"\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(ggplot2)\ndiamonds %>% filter(cut == \"Ideal\")\n#> # A tibble: 21,551 × 10\n#>    carat cut   color clarity depth table price     x     y\n#>    <dbl> <ord> <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl>\n#>  1  0.23 Ideal E     SI2      61.5    55   326  3.95  3.98\n#>  2  0.23 Ideal J     VS1      62.8    56   340  3.93  3.9 \n#>  3  0.31 Ideal J     SI2      62.2    54   344  4.35  4.37\n#>  4  0.3  Ideal I     SI2      62      54   348  4.31  4.34\n#>  5  0.33 Ideal I     SI2      61.8    55   403  4.49  4.51\n#>  6  0.33 Ideal I     SI2      61.2    56   403  4.49  4.5 \n#>  7  0.33 Ideal J     SI1      61.1    56   403  4.49  4.55\n#>  8  0.23 Ideal G     VS1      61.9    54   404  3.93  3.95\n#>  9  0.32 Ideal I     SI1      60.9    55   404  4.45  4.48\n#> 10  0.3  Ideal I     SI2      61      59   405  4.3   4.33\n#> # ℹ 21,541 more rows\n#> # ℹ 1 more variable: z <dbl>"},{"path":"part-ii-data-wrangling.html","id":"filter","chapter":"Part II: Data Wrangling","heading":"Filter()","text":"Extract rows meet logical criteria. go:\n- inspect diamonds data set\n- filter observations cut equal Ideal","code":"\nfilter(diamonds, cut == \"Ideal\")\n#> # A tibble: 21,551 × 10\n#>    carat cut   color clarity depth table price     x     y\n#>    <dbl> <ord> <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl>\n#>  1  0.23 Ideal E     SI2      61.5    55   326  3.95  3.98\n#>  2  0.23 Ideal J     VS1      62.8    56   340  3.93  3.9 \n#>  3  0.31 Ideal J     SI2      62.2    54   344  4.35  4.37\n#>  4  0.3  Ideal I     SI2      62      54   348  4.31  4.34\n#>  5  0.33 Ideal I     SI2      61.8    55   403  4.49  4.51\n#>  6  0.33 Ideal I     SI2      61.2    56   403  4.49  4.5 \n#>  7  0.33 Ideal J     SI1      61.1    56   403  4.49  4.55\n#>  8  0.23 Ideal G     VS1      61.9    54   404  3.93  3.95\n#>  9  0.32 Ideal I     SI1      60.9    55   404  4.45  4.48\n#> 10  0.3  Ideal I     SI2      61      59   405  4.3   4.33\n#> # ℹ 21,541 more rows\n#> # ℹ 1 more variable: z <dbl>"},{"path":"part-ii-data-wrangling.html","id":"overview-of-logical-tests","chapter":"Part II: Data Wrangling","heading":"Overview of logical tests","text":"","code":""},{"path":"part-ii-data-wrangling.html","id":"mutate","chapter":"Part II: Data Wrangling","heading":"Mutate()","text":"Create new columns. go:\n- inspect diamonds data set\n- create new variable price_per_carat","code":"\nmutate(diamonds, price_per_carat = price/carat)\n#> # A tibble: 53,940 × 11\n#>    carat cut     color clarity depth table price     x     y\n#>    <dbl> <ord>   <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl>\n#>  1  0.23 Ideal   E     SI2      61.5    55   326  3.95  3.98\n#>  2  0.21 Premium E     SI1      59.8    61   326  3.89  3.84\n#>  3  0.23 Good    E     VS1      56.9    65   327  4.05  4.07\n#>  4  0.29 Premium I     VS2      62.4    58   334  4.2   4.23\n#>  5  0.31 Good    J     SI2      63.3    58   335  4.34  4.35\n#>  6  0.24 Very G… J     VVS2     62.8    57   336  3.94  3.96\n#>  7  0.24 Very G… I     VVS1     62.3    57   336  3.95  3.98\n#>  8  0.26 Very G… H     SI1      61.9    55   337  4.07  4.11\n#>  9  0.22 Fair    E     VS2      65.1    61   337  3.87  3.78\n#> 10  0.23 Very G… H     VS1      59.4    61   338  4     4.05\n#> # ℹ 53,930 more rows\n#> # ℹ 2 more variables: z <dbl>, price_per_carat <dbl>"},{"path":"part-ii-data-wrangling.html","id":"multistep-operations","chapter":"Part II: Data Wrangling","heading":"Multistep operations","text":"Use %>% multistep operations.\nPasses result left first argument function right. go:","code":"\ndiamonds %>% \n  mutate(price_per_carat = price/carat)  %>%\n  filter(price_per_carat > 1500)\n#> # A tibble: 52,821 × 11\n#>    carat cut     color clarity depth table price     x     y\n#>    <dbl> <ord>   <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl>\n#>  1  0.21 Premium E     SI1      59.8    61   326  3.89  3.84\n#>  2  0.22 Fair    E     VS2      65.1    61   337  3.87  3.78\n#>  3  0.22 Premium F     SI1      60.4    61   342  3.88  3.84\n#>  4  0.2  Premium E     SI2      60.2    62   345  3.79  3.75\n#>  5  0.23 Very G… E     VS2      63.8    55   352  3.85  3.92\n#>  6  0.23 Very G… H     VS1      61      57   353  3.94  3.96\n#>  7  0.23 Very G… G     VVS2     60.4    58   354  3.97  4.01\n#>  8  0.23 Very G… D     VS2      60.5    61   357  3.96  3.97\n#>  9  0.23 Very G… F     VS1      60.9    57   357  3.96  3.99\n#> 10  0.23 Very G… F     VS1      60      57   402  4     4.03\n#> # ℹ 52,811 more rows\n#> # ℹ 2 more variables: z <dbl>, price_per_carat <dbl>"},{"path":"part-ii-data-wrangling.html","id":"summarize","chapter":"Part II: Data Wrangling","heading":"Summarize()","text":"Compute table summaries. go:inspect diamonds data setcalculate mean standard deviation price","code":"\ndiamonds %>% summarize(mean = mean(price), std_dev = sd(price))\n#> # A tibble: 1 × 2\n#>    mean std_dev\n#>   <dbl>   <dbl>\n#> 1 3933.   3989."},{"path":"part-ii-data-wrangling.html","id":"group_by","chapter":"Part II: Data Wrangling","heading":"Group_by()","text":"Groups cases common values one columns. go:\ninspect diamonds data set\ncalculate mean standard deviation price level cut","code":"\ndiamonds %>% \n        group_by(cut) %>% \n        summarize(price = mean(price), carat = mean(carat))\n#> # A tibble: 5 × 3\n#>   cut       price carat\n#>   <ord>     <dbl> <dbl>\n#> 1 Fair      4359. 1.05 \n#> 2 Good      3929. 0.849\n#> 3 Very Good 3982. 0.806\n#> 4 Premium   4584. 0.892\n#> 5 Ideal     3458. 0.703"},{"path":"part-ii-data-wrangling.html","id":"exercise-1-5","chapter":"Part II: Data Wrangling","heading":"Exercise 1","text":"Load data Parade2005.txt.Determine mean earnings California.Determine number individuals residing Idaho.Determine mean median earnings celebrities.","code":""},{"path":"part-ii-data-wrangling.html","id":"transforming-a-dataframe-into-tibbles","chapter":"Part II: Data Wrangling","heading":"Transforming a dataframe into tibbles","text":"Transform mtcars tibble inspect.","code":"\nstr(mtcars)\n#> 'data.frame':    32 obs. of  11 variables:\n#>  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n#>  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n#>  $ disp: num  160 160 108 258 360 ...\n#>  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n#>  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n#>  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n#>  $ qsec: num  16.5 17 18.6 19.4 17 ...\n#>  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n#>  $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n#>  $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n#>  $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n#library(tidyverse)\nlibrary(tibble)\nas_tibble(mtcars)\n#> # A tibble: 32 × 11\n#>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am\n#>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n#>  1  21       6  160    110  3.9   2.62  16.5     0     1\n#>  2  21       6  160    110  3.9   2.88  17.0     0     1\n#>  3  22.8     4  108     93  3.85  2.32  18.6     1     1\n#>  4  21.4     6  258    110  3.08  3.22  19.4     1     0\n#>  5  18.7     8  360    175  3.15  3.44  17.0     0     0\n#>  6  18.1     6  225    105  2.76  3.46  20.2     1     0\n#>  7  14.3     8  360    245  3.21  3.57  15.8     0     0\n#>  8  24.4     4  147.    62  3.69  3.19  20       1     0\n#>  9  22.8     4  141.    95  3.92  3.15  22.9     1     0\n#> 10  19.2     6  168.   123  3.92  3.44  18.3     1     0\n#> # ℹ 22 more rows\n#> # ℹ 2 more variables: gear <dbl>, carb <dbl>"},{"path":"part-ii-data-wrangling.html","id":"part-ii-data-cleaning-and-transformation","chapter":"Part II: Data Wrangling","heading":"Part II : Data Cleaning and Transformation","text":"Data cleaning info","code":""},{"path":"part-ii-data-wrangling.html","id":"the-policy-data-set","chapter":"Part II: Data Wrangling","heading":"The Policy data set","text":"PolicyData.csv available course materialData stored .csv file.Individual records separated semicolon.","code":"\npolicy_data <- read.csv(file = './John Jay Workshop Data/PolicyData.csv', sep = ';')"},{"path":"part-ii-data-wrangling.html","id":"exercise-1-6","chapter":"Part II: Data Wrangling","heading":"Exercise 1","text":"Use skills obtained first R workshop.Inspect top rows data set.many observations data set contain?Calculate total exposure (exposition) region (type_territoire).","code":""},{"path":"part-ii-data-wrangling.html","id":"the-gapminder-package","chapter":"Part II: Data Wrangling","heading":"The Gapminder package","text":"Describes evolution number population characteristics (GDP, life expectancy, …) time.","code":"\n#install.packages(\"gapminder\")\nlibrary(gapminder)"},{"path":"part-ii-data-wrangling.html","id":"exercise-2-3","chapter":"Part II: Data Wrangling","heading":"Exercise 2","text":"Use skills obtained Part :Inspect top rows data.Select data countries Asia.type variable country?","code":""},{"path":"part-ii-data-wrangling.html","id":"revisit-factor","chapter":"Part II: Data Wrangling","heading":"Revisit factor()","text":"","code":""},{"path":"part-ii-data-wrangling.html","id":"what-is-a-factor-variable","chapter":"Part II: Data Wrangling","heading":"What is a factor variable ?","text":"Representation categorical data.Predefined list outcomes (levels).Protecting data quality.Example , sex categorical value two possible outcomes, m fThe factor command creates new factor variable. first input categorical variable.factor command creates new factor variable. first input categorical variable.levels specifies possible outcomes variable.levels specifies possible outcomes variable.Assigning unrecognized level factor variable results warningThis protects quality dataThe value NA assigned invalid observation.","code":"\nsex <- factor(c('m', 'f', 'm', 'f'),\n              levels = c('m', 'f'))\nsex\n#> [1] m f m f\n#> Levels: m f\nsex[1] <- 'male'\n#> Warning in `[<-.factor`(`*tmp*`, 1, value = \"male\"):\n#> invalid factor level, NA generated\nsex\n#> [1] <NA> f    m    f   \n#> Levels: m f"},{"path":"part-ii-data-wrangling.html","id":"levels","chapter":"Part II: Data Wrangling","heading":"levels()","text":"levels print allowed outcomes factor variableAssigning vector levels() renames allowed outcomes.","code":"\nlevels(sex)\n#> [1] \"m\" \"f\"\nlevels(sex) <- c('male', 'female')\nsex\n#> [1] <NA>   female male   female\n#> Levels: male female"},{"path":"part-ii-data-wrangling.html","id":"exercise-4-2","chapter":"Part II: Data Wrangling","heading":"Exercise 4","text":"variable country gapminder data set factor variable.possible levels country subset asia.result expected?add level","code":"\nlevels(sex) <- c(levels(sex), 'x')"},{"path":"part-ii-data-wrangling.html","id":"cut","chapter":"Part II: Data Wrangling","heading":"cut()","text":"","code":"\ngapminder\n#> # A tibble: 1,704 × 6\n#>    country     continent  year lifeExp      pop gdpPercap\n#>    <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n#>  1 Afghanistan Asia       1952    28.8  8425333      779.\n#>  2 Afghanistan Asia       1957    30.3  9240934      821.\n#>  3 Afghanistan Asia       1962    32.0 10267083      853.\n#>  4 Afghanistan Asia       1967    34.0 11537966      836.\n#>  5 Afghanistan Asia       1972    36.1 13079460      740.\n#>  6 Afghanistan Asia       1977    38.4 14880372      786.\n#>  7 Afghanistan Asia       1982    39.9 12881816      978.\n#>  8 Afghanistan Asia       1987    40.8 13867957      852.\n#>  9 Afghanistan Asia       1992    41.7 16317921      649.\n#> 10 Afghanistan Asia       1997    41.8 22227415      635.\n#> # ℹ 1,694 more rows\nhead(cut(gapminder$pop,\n    breaks = c(0, 10^7, 5*10^7, 10^8, Inf)))\n#> [1] (0,1e+07]     (0,1e+07]     (1e+07,5e+07] (1e+07,5e+07]\n#> [5] (1e+07,5e+07] (1e+07,5e+07]\n#> 4 Levels: (0,1e+07] (1e+07,5e+07] ... (1e+08,Inf]\ngapminder$pop_category = cut(gapminder$pop,\n                             breaks = c(0, 10^7, 5*10^7, 10^8, Inf),\n                             labels = c(\"<= 10M\", \"10M-50M\", \"50M-100M\", \"> 100M\"))\ngapminder\n#> # A tibble: 1,704 × 7\n#>    country     continent  year lifeExp      pop gdpPercap\n#>    <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n#>  1 Afghanistan Asia       1952    28.8  8425333      779.\n#>  2 Afghanistan Asia       1957    30.3  9240934      821.\n#>  3 Afghanistan Asia       1962    32.0 10267083      853.\n#>  4 Afghanistan Asia       1967    34.0 11537966      836.\n#>  5 Afghanistan Asia       1972    36.1 13079460      740.\n#>  6 Afghanistan Asia       1977    38.4 14880372      786.\n#>  7 Afghanistan Asia       1982    39.9 12881816      978.\n#>  8 Afghanistan Asia       1987    40.8 13867957      852.\n#>  9 Afghanistan Asia       1992    41.7 16317921      649.\n#> 10 Afghanistan Asia       1997    41.8 22227415      635.\n#> # ℹ 1,694 more rows\n#> # ℹ 1 more variable: pop_category <fct>"},{"path":"part-ii-data-wrangling.html","id":"exercise-5-2","chapter":"Part II: Data Wrangling","heading":"Exercise 5","text":"Bin life expectancy 2007 factor variable.\n1. Select observations year 2007.\n2. Bin life expectancy four bins roughly equal size (hint: quantile).\n3. many observations bin?","code":""},{"path":"part-ii-data-wrangling.html","id":"handling-missing-data","chapter":"Part II: Data Wrangling","heading":"Handling missing data","text":"","code":""},{"path":"part-ii-data-wrangling.html","id":"some-history","chapter":"Part II: Data Wrangling","heading":"Some history","text":"practice imputing missing values evolved significantly years statisticians data scientists sought deal unavoidable problem incomplete data. history imputation reflects broader trends statistical methods computational capabilities, well growing awareness impacts different imputation strategies integrity statistical analysis.","code":""},{"path":"part-ii-data-wrangling.html","id":"missing-data-mechanisms","chapter":"Part II: Data Wrangling","heading":"Missing Data Mechanisms","text":"Rubin (1976) classified missing data 3 categories:\n- Missing Completely Random (MCAR)\n- Missing Random (MAR)\n- Missing Random (NMAR), also called Missing Random (MNAR)\n- Aka confusing statistical terms ever invented","code":""},{"path":"part-ii-data-wrangling.html","id":"early-approaches-and-simple-imputation","chapter":"Part II: Data Wrangling","heading":"Early Approaches and Simple Imputation","text":"Early approaches handling missing data often quite simple, including methods like listwise deletion (removing record missing value) pairwise deletion (excluding missing values case--case basis analysis). methods, straightforward, can lead biased results reduced statistical power missingness completely random.Simple imputation techniques, filling missing values mean, median, mode variable, developed way retain much data possible. methods easy understand implement, contributed widespread use, especially era advanced computational methods became widely accessible.","code":""},{"path":"part-ii-data-wrangling.html","id":"limitations-of-mean-and-median-imputation","chapter":"Part II: Data Wrangling","heading":"Limitations of Mean and Median Imputation","text":"Imputing missing values mean median intuitive can effective certain contexts, methods significant limitations:Bias Estimation: Mean median imputation account inherent uncertainty associated missing data. can lead underestimation variances covariances artificially reduce variability imputed variable.Distortion Data Distribution: methods can distort original distribution data, especially missingness random (Missing Random - MNAR) proportion missing data high. distortion can affect subsequent analyses, regression models, providing misleading results.Ignores Relationships Variables: Mean median imputation treat variable isolation, ignoring potential relationships variables. can particularly problematic multivariate datasets variables may correlated.","code":""},{"path":"part-ii-data-wrangling.html","id":"modern-imputation-techniques","chapter":"Part II: Data Wrangling","heading":"Modern Imputation Techniques","text":"awareness limitations simple imputation methods grew, researchers developed sophisticated techniques designed address shortcomings:Multiple Imputation: Developed late 20th century, multiple imputation involves creating several imputed datasets drawing distribution reflects uncertainty around true values missing data. datasets analyzed separately, results combined produce estimates account uncertainty due missingness. method addresses issue underestimating variability provides reliable statistical inferences.Model-Based Imputation: Techniques like Expectation-Maximization (EM) algorithms imputation using random forests machine learning models take account relationships variables dataset. methods can accurately reflect complex structures data produce imputations preserve statistical relationships.ConclusionThe evolution imputation methods simple mean median filling sophisticated model-based multiple imputation techniques reflects broader shift statistical practice. shift characterized increased computational power, complex datasets, deeper understanding impact missing data statistical inference. mean median imputation can still useful specific, well-considered circumstances, modern techniques offer robust principled approaches handling missing data.","code":""},{"path":"part-ii-data-wrangling.html","id":"missing-values-in-r","chapter":"Part II: Data Wrangling","heading":"Missing Values in R","text":"Missing values denoted NA NaN q undefined mathematical operations..na() used test objects NAis.nan() used test NaNNA values class also, integer NA, character NA, etc.NaN value also NA converse true","code":""},{"path":"part-ii-data-wrangling.html","id":"difference-between-na-and-nan-in-r","chapter":"Part II: Data Wrangling","heading":"0.0.1 Difference Between NA and NaN in R","text":"R, NA NaN represent two different kinds missing undefined values, used distinct contexts:","code":""},{"path":"part-ii-data-wrangling.html","id":"na-not-available","chapter":"Part II: Data Wrangling","heading":"0.0.1.1 NA (Not Available)","text":"NA stands Available.used represent missing undefined data, typically cases data expected present.NA can used logical statistical operation, unless handled specifically, operations involving NA generally result NA.NA flexible context can used data type R, numeric, character, logical.can test NA using .na() function.","code":""},{"path":"part-ii-data-wrangling.html","id":"nan-not-a-number","chapter":"Part II: Data Wrangling","heading":"0.0.1.2 NaN (Not a Number)","text":"NaN stands Number.special value used represent undefined unrepresentable numerical results, result 0/0.NaN specific type NA specifically numeric calculations result undefined indeterminate values.Operations result NaN typically mathematically indeterminate outside domain mathematical functions (e.g., square root negative number realm real numbers).can test NaN using .nan() function. Note .na() also returns TRUE NaN values, reflecting status kind missing value, .nan() return TRUE NA values.","code":""},{"path":"part-ii-data-wrangling.html","id":"key-differences","chapter":"Part II: Data Wrangling","heading":"Key Differences","text":"Context Use: NA used broadly missing data across data types, NaN specific numerical operations produce defined, real number.Nature Undefinedness: NA indicates absence data, whereas NaN indicates calculation failed produce meaningful result.summary, use NA vs. NaN helps distinguish data missing (NA) numerical operations result undefined unrepresentable values (NaN).","code":"\ncoffee_data <- data.frame(\n  Age = c(25, 32, NA, 45, 22, 33, NA, 28),\n  Gender = c(\"Female\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", NA),\n  Cups_Per_Day = c(1, 3, 2, NA, 2, 3, 1, 2)\n)\ncoffee_data\n#>   Age Gender Cups_Per_Day\n#> 1  25 Female            1\n#> 2  32   Male            3\n#> 3  NA   Male            2\n#> 4  45 Female           NA\n#> 5  22 Female            2\n#> 6  33   Male            3\n#> 7  NA Female            1\n#> 8  28   <NA>            2"},{"path":"part-ii-data-wrangling.html","id":"identifying-missing-values","chapter":"Part II: Data Wrangling","heading":"Identifying Missing Values","text":"can use .na() function check missing values. count specific column:","code":"\nsum(is.na(coffee_data$Age))\n#> [1] 2"},{"path":"part-ii-data-wrangling.html","id":"removing-na-values","chapter":"Part II: Data Wrangling","heading":"Removing NA Values","text":"common task data analysis removing missing values (NAs).can remove byA faster way ,","code":"\nx <- c(1, 2, NA, 4, NA, 5)\nbad <- is.na(x)\nprint(bad)\n#> [1] FALSE FALSE  TRUE FALSE  TRUE FALSE\nx[!bad]\n#> [1] 1 2 4 5\nx[!is.na(x)]\n#> [1] 1 2 4 5"},{"path":"part-ii-data-wrangling.html","id":"in-a-data-frame","chapter":"Part II: Data Wrangling","heading":"In a Data frame","text":"Also, using coffee example,remove rows missing values specific column:multiple R objects want take subset missing values objects?can use complete.cases data frames .","code":"\ncoffee_data_clean <- na.omit(coffee_data)\ncoffee_data_clean\n#>   Age Gender Cups_Per_Day\n#> 1  25 Female            1\n#> 2  32   Male            3\n#> 5  22 Female            2\n#> 6  33   Male            3\n\ncoffee_data_clean2 <- coffee_data[!is.na(coffee_data$Age), ]\ncoffee_data_clean2\n#>   Age Gender Cups_Per_Day\n#> 1  25 Female            1\n#> 2  32   Male            3\n#> 4  45 Female           NA\n#> 5  22 Female            2\n#> 6  33   Male            3\n#> 8  28   <NA>            2\nrow.names(coffee_data_clean2) <- NULL\ncoffee_data_clean2\n#>   Age Gender Cups_Per_Day\n#> 1  25 Female            1\n#> 2  32   Male            3\n#> 3  45 Female           NA\n#> 4  22 Female            2\n#> 5  33   Male            3\n#> 6  28   <NA>            2\nx <- c(1, 2, NA, 4, NA, 5)\ny <- c(\"a\", \"b\", NA, \"d\", NA, \"f\")\ngood <- complete.cases(x, y)\ngood\n#> [1]  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nx[good]\n#> [1] 1 2 4 5\ny[good]\n#> [1] \"a\" \"b\" \"d\" \"f\"\nhead(airquality)\n#>   Ozone Solar.R Wind Temp Month Day\n#> 1    41     190  7.4   67     5   1\n#> 2    36     118  8.0   72     5   2\n#> 3    12     149 12.6   74     5   3\n#> 4    18     313 11.5   62     5   4\n#> 5    NA      NA 14.3   56     5   5\n#> 6    28      NA 14.9   66     5   6\ngood <- complete.cases(airquality)\nhead(airquality[good, ])\n#>   Ozone Solar.R Wind Temp Month Day\n#> 1    41     190  7.4   67     5   1\n#> 2    36     118  8.0   72     5   2\n#> 3    12     149 12.6   74     5   3\n#> 4    18     313 11.5   62     5   4\n#> 7    23     299  8.6   65     5   7\n#> 8    19      99 13.8   59     5   8\nsd(airquality$Ozone)\n#> [1] NA\nsd(airquality$Ozone, na.rm = TRUE)\n#> [1] 32.98788"},{"path":"part-ii-data-wrangling.html","id":"imputing-missing-values","chapter":"Part II: Data Wrangling","heading":"Imputing Missing Values","text":"Replacing missing values specific value, like mean median:","code":"\ncoffee_data2<-coffee_data\n\ncoffee_data2$Age[is.na(coffee_data$Age)] <- mean(coffee_data2$Age, na.rm = TRUE)\ncoffee_data2\n#>        Age Gender Cups_Per_Day\n#> 1 25.00000 Female            1\n#> 2 32.00000   Male            3\n#> 3 30.83333   Male            2\n#> 4 45.00000 Female           NA\n#> 5 22.00000 Female            2\n#> 6 33.00000   Male            3\n#> 7 30.83333 Female            1\n#> 8 28.00000   <NA>            2\n# Assuming 'median' is the mode of the column\nmedian(coffee_data$Age, na.rm = TRUE)\n#> [1] 30\ncoffee_data2$Age[is.na(coffee_data$Age)] <- median(coffee_data$Age, na.rm = TRUE)\ncoffee_data2\n#>   Age Gender Cups_Per_Day\n#> 1  25 Female            1\n#> 2  32   Male            3\n#> 3  30   Male            2\n#> 4  45 Female           NA\n#> 5  22 Female            2\n#> 6  33   Male            3\n#> 7  30 Female            1\n#> 8  28   <NA>            2"},{"path":"part-ii-data-wrangling.html","id":"using-packages-for-advanced-imputation","chapter":"Part II: Data Wrangling","heading":"Using Packages for Advanced Imputation","text":"","code":"\n# install.packages(\"mice\")\nlibrary(mice)\n#> \n#> Attaching package: 'mice'\n#> The following object is masked from 'package:stats':\n#> \n#>     filter\n#> The following objects are masked from 'package:base':\n#> \n#>     cbind, rbind\n# Display the first few rows of the airquality dataset\nhead(airquality)\n#>   Ozone Solar.R Wind Temp Month Day\n#> 1    41     190  7.4   67     5   1\n#> 2    36     118  8.0   72     5   2\n#> 3    12     149 12.6   74     5   3\n#> 4    18     313 11.5   62     5   4\n#> 5    NA      NA 14.3   56     5   5\n#> 6    28      NA 14.9   66     5   6\n\n# Perform multiple imputation\nimputed_data <- mice(airquality, m=5, method='pmm', seed = 123)\n#> \n#>  iter imp variable\n#>   1   1  Ozone  Solar.R\n#>   1   2  Ozone  Solar.R\n#>   1   3  Ozone  Solar.R\n#>   1   4  Ozone  Solar.R\n#>   1   5  Ozone  Solar.R\n#>   2   1  Ozone  Solar.R\n#>   2   2  Ozone  Solar.R\n#>   2   3  Ozone  Solar.R\n#>   2   4  Ozone  Solar.R\n#>   2   5  Ozone  Solar.R\n#>   3   1  Ozone  Solar.R\n#>   3   2  Ozone  Solar.R\n#>   3   3  Ozone  Solar.R\n#>   3   4  Ozone  Solar.R\n#>   3   5  Ozone  Solar.R\n#>   4   1  Ozone  Solar.R\n#>   4   2  Ozone  Solar.R\n#>   4   3  Ozone  Solar.R\n#>   4   4  Ozone  Solar.R\n#>   4   5  Ozone  Solar.R\n#>   5   1  Ozone  Solar.R\n#>   5   2  Ozone  Solar.R\n#>   5   3  Ozone  Solar.R\n#>   5   4  Ozone  Solar.R\n#>   5   5  Ozone  Solar.R\n\n# Extract the first completed dataset\ncompleted_data <- complete(imputed_data, 1)\n\n# Display the first few rows of the completed data\nhead(completed_data)\n#>   Ozone Solar.R Wind Temp Month Day\n#> 1    41     190  7.4   67     5   1\n#> 2    36     118  8.0   72     5   2\n#> 3    12     149 12.6   74     5   3\n#> 4    18     313 11.5   62     5   4\n#> 5    18     150 14.3   56     5   5\n#> 6    28      48 14.9   66     5   6"},{"path":"part-ii-data-wrangling.html","id":"exercise-1-explore-missingness","chapter":"Part II: Data Wrangling","heading":"Exercise 1: Explore Missingness","text":"Dataset: ChickWeightTask: Determine ChickWeight dataset contains missing values. Print message stating whether dataset missing values .Hint Use () function combined .na() applied dataset.","code":""},{"path":"part-ii-data-wrangling.html","id":"exercise-2-calculate-summary-statistics-before-handling-na","chapter":"Part II: Data Wrangling","heading":"Exercise 2: Calculate Summary Statistics Before Handling NA","text":"Dataset: mtcarsTask: mtcars dataset almost complete let’s pretend values missing mpg (miles per gallon) column. First, artificially introduce missing values mpg column (e.g., set first three values mpg NA). , calculate print mean standard deviation mpg without removing imputing missing values.Hint: Modify mtcars$mpg directly introduce NAs. Use mean() sd() functions na.rm = FALSE calculate statistics without handling NA.","code":"\ndata(mtcars)\nmean_mpg <- mean(mtcars$mpg)\nmean_mpg\n#> [1] 20.09062\nsd_mpg <- sd(mtcars$mpg)\nsd_mpg\n#> [1] 6.026948"},{"path":"part-ii-data-wrangling.html","id":"exercise-3-impute-missing-values-with-column-median","chapter":"Part II: Data Wrangling","heading":"Exercise 3: Impute Missing Values with Column Median","text":"Dataset: mtcars modified mpgTask: First Calculate mean standard deviation handling missing values.,Impute artificially introduced missing values mpg column column’s median (excluding missing values). Print first 6 rows modified mtcars dataset.Now, calculate mean standard deviation imputed values.Hint: First, calculate median mpg excluding NAs. , use indexing replace NAs median.","code":""},{"path":"part-ii-data-wrangling.html","id":"exercise-4-identifying-complete-rows","chapter":"Part II: Data Wrangling","heading":"Exercise 4: Identifying Complete Rows","text":"Dataset: airqualityTask: analysis, want ensure complete cases used. Create new dataset airquality includes rows without missing values. Print number rows original versus cleaned dataset.Hint Use complete.cases() dataset subset .","code":""},{"path":"part-ii-data-wrangling.html","id":"exercise-5-advanced-imputation-on-a-subset","chapter":"Part II: Data Wrangling","heading":"Exercise 5: Advanced Imputation on a Subset","text":"Dataset: mtcarsTask: Create subset mtcars containing mpg, hp (horsepower), wt (weight) columns. Introduce missing values hp wt columns (e.g., set first two values NA). Perform multiple imputation using mice package subset 3 imputations, extract third completed dataset. Print first 6 rows completed dataset.Hint: Subset mtcars first, modify add NAs. Use mice() imputation complete() extract desired imputed dataset.","code":""},{"path":"intermediate-r-ii.html","id":"intermediate-r-ii","chapter":"Intermediate R II","heading":"Intermediate R II","text":"session , advanced data visualization ,statistical analysis.time permits, cover Dates Times","code":""},{"path":"part-i-advanced-data-visualization.html","id":"part-i-advanced-data-visualization","chapter":"Part I: Advanced Data Visualization","heading":"Part I: Advanced Data Visualization","text":"aim ggplot2 package create elegant data visualizations using grammar graphics.basic steps:begin plot function ggplot() creating coordinate system can add layers -first argument ggplot() dataset use graphWe use mpg dataset ggplot2Run following code,obtain ?complete graph adding one layers ggplot()example:\n- geom_point() adds layer points plot, creates scatterplot\n- geom_smooth() adds smooth line\n- geom_bar bar plot.geom function ggplot2 takes mapping argument:\n- variables dataset mapped visual properties\n- always paired aes() arguments aes() specify variables map axes.Compare following set instructions:inside aestheticsinside aesthetics, mapped variableoutside aestheticsScatterplotboxplothistogramNow add multiple geoms plot.\nPredict following code :Mappings data can specified global (ggplot()) local.local.","code":"\nlibrary(ggplot2)\nhead(mpg)\n#> # A tibble: 6 × 11\n#>   manufacturer model displ  year   cyl trans     drv     cty\n#>   <chr>        <chr> <dbl> <int> <int> <chr>     <chr> <int>\n#> 1 audi         a4      1.8  1999     4 auto(l5)  f        18\n#> 2 audi         a4      1.8  1999     4 manual(m… f        21\n#> 3 audi         a4      2    2008     4 manual(m… f        20\n#> 4 audi         a4      2    2008     4 auto(av)  f        21\n#> 5 audi         a4      2.8  1999     6 auto(l5)  f        16\n#> 6 audi         a4      2.8  1999     6 manual(m… f        18\n#> # ℹ 3 more variables: hwy <int>, fl <chr>, class <chr>\n\nggplot(data = mpg)\nggplot(mpg)\nlibrary(ggplot2)\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\nggplot(data = mpg) + geom_point(aes(x = displ, y = hwy, color = class))\nggplot(mpg) + geom_point(aes(x = displ, y = hwy, color = class))\nggplot(mpg) + geom_point(aes(x = displ, y = hwy, color = \"blue\"))\nggplot(mpg) + geom_point(aes(x = displ, y = hwy), color = \"blue\")\nggplot(mpg) + \n  geom_point(mapping = aes(x = class, y = hwy))\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = class, y = hwy))\nggplot(data = mpg) +\n  geom_histogram(mapping = aes(x = hwy))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = mpg) +\n  geom_density(mapping = aes(x = hwy))\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~\n#> x'\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +\n  geom_point() +\n  geom_smooth() + theme_bw()       # adjust theme\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~\n#> x'\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +\n  geom_point(mapping = aes(color = drv)) +\n  geom_smooth() + theme_bw()\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~\n#> x'\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +\n  geom_point(mapping = aes(color = drv)) +\n  geom_smooth(data = filter(mpg, drv == \"f\")) + theme_bw()\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~\n#> x'"},{"path":"part-i-advanced-data-visualization.html","id":"exercise-1-7","chapter":"Part I: Advanced Data Visualization","heading":"Exercise 1","text":"Use Danish fire insurance losses. Plot arrival losses time.Use type= “l” line plot, label -axis, give plot title using main.instructions ggplot2. Use geom_line() create line plot.","code":""},{"path":"part-i-advanced-data-visualization.html","id":"exercise-2-4","chapter":"Part I: Advanced Data Visualization","heading":"Exercise 2","text":"Use data set car_price.csv available documentation. Import data R.Use data set car_price.csv available documentation. Import data R.Explore data.Explore data.Make scatterplot price versus income, use basic plotting instructions\nuse ggplot2.Make scatterplot price versus income, use basic plotting instructions\nuse ggplot2.Add smooth line plots (using lines add line existing plot lowess scatterplot smoothing using geom_smooth ggplot2 grammar).Add smooth line plots (using lines add line existing plot lowess scatterplot smoothing using geom_smooth ggplot2 grammar).","code":""},{"path":"part-i-advanced-data-visualization.html","id":"creating-customized-plots-with-ggplot2","chapter":"Part I: Advanced Data Visualization","heading":"Creating customized plots with ggplot2","text":"","code":"\n\n# Load ggplot2 package\nlibrary(ggplot2)\n\n# Example: Customized scatter plot with ggplot2\ndata <- data.frame(x = rnorm(100), y = rnorm(100))\nggplot(data, aes(x = x, y = y)) +\n  geom_point(aes(color = x*y), size = 3) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  ggtitle(\"Customized Scatter Plot with Color Gradient\") +\n  theme_minimal()"},{"path":"part-i-advanced-data-visualization.html","id":"adding-titles-labels-and-themes-to-plots","chapter":"Part I: Advanced Data Visualization","heading":"Adding titles, labels, and themes to plots","text":"","code":"\n# Example: Enhanced bar plot with titles, labels, and a custom theme\ndata <- data.frame(\n  category = c(\"A\", \"B\", \"C\", \"D\"),\n  value = c(10, 15, 7, 12)\n)\nggplot(data, aes(x = category, y = value, fill = category)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Enhanced Bar Plot\",\n       subtitle = \"Bar plot with custom labels and theme\",\n       x = \"Category\",\n       y = \"Value\",\n       fill = \"Category\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))"},{"path":"part-ii-statistical-analysis.html","id":"part-ii-statistical-analysis","chapter":"Part II: Statistical Analysis","heading":"Part II: Statistical Analysis","text":"","code":""},{"path":"part-ii-statistical-analysis.html","id":"introduction-to-hypothesis-testing-and-statistical-tests","chapter":"Part II: Statistical Analysis","heading":"Introduction to hypothesis testing and statistical tests","text":"Hypothesis testing statistical method used make inferences draw conclusions population based sample data. starts null hypothesis (H0) assumes effect difference, alternative hypothesis (H1) contradicts null hypothesis.process involves:\n1. Defining null alternative hypotheses.\n2. Selecting significance level (alpha, typically 0.05).\n3. Calculating test statistic based sample data.\n4. Determining p-value, probability observing test statistic something extreme null hypothesis.\n5. Comparing p-value significance level decide whether reject null hypothesis.Statistical tests vary based type data research question. Common tests include t-tests (means), chi-squared tests (categorical data), ANOVA (comparing means across multiple groups), regression analysis (relationships variables).","code":""},{"path":"part-ii-statistical-analysis.html","id":"performing-t-tests-and-chi-squared-tests","chapter":"Part II: Statistical Analysis","heading":"Performing t-tests and chi-squared tests","text":"","code":"\n# Load necessary libraries\nlibrary(stats)\n\n# Example: Performing a t-test\n# Hypothesis: The mean of a sample is different from the population mean (which we assume to be 0 for this example).\n\nsample_data <- rnorm(30)  # Generating a sample of 30 random normal numbers\nt_test_result <- t.test(sample_data, mu = 0)  # Performing a one-sample t-test\nprint(t_test_result)\n#> \n#>  One Sample t-test\n#> \n#> data:  sample_data\n#> t = 0.60232, df = 29, p-value = 0.5516\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.2369447  0.4347610\n#> sample estimates:\n#>  mean of x \n#> 0.09890814\n\n# Example: Performing a chi-squared test\n# Hypothesis: Two categorical variables are independent.\n\n# Creating a sample contingency table\nobserved <- matrix(c(10, 10, 20, 20), nrow = 2, byrow = TRUE)\ndimnames(observed) <- list(gender = c(\"Male\", \"Female\"), preference = c(\"Option A\", \"Option B\"))\n\nchi_squared_test_result <- chisq.test(observed)  # Performing the chi-squared test\nprint(chi_squared_test_result)\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  observed\n#> X-squared = 0, df = 1, p-value = 1"},{"path":"optional-part-v-working-with-dates-and-times-20-minutes.html","id":"optional-part-v-working-with-dates-and-times-20-minutes","chapter":"(Optional) Part V: Working with Dates and Times (20 minutes)","heading":"(Optional) Part V: Working with Dates and Times (20 minutes)","text":"","code":""},{"path":"optional-part-v-working-with-dates-and-times-20-minutes.html","id":"handling-date-and-time-data-in-r","chapter":"(Optional) Part V: Working with Dates and Times (20 minutes)","heading":"Handling date and time data in R","text":"R provides Date class dates POSIXct POSIXlt classes times.","code":"\n# Converting a string to a Date object\ndate_example <- as.Date(\"2021-01-01\")\nprint(date_example)\n#> [1] \"2021-01-01\"\n\n# Converting a string to a POSIXct datetime object\ndatetime_example <- as.POSIXct(\"2021-01-01 10:00:00\", tz = \"GMT\")\nprint(datetime_example)\n#> [1] \"2021-01-01 10:00:00 GMT\""},{"path":"optional-part-v-working-with-dates-and-times-20-minutes.html","id":"common-date-and-time-functions","chapter":"(Optional) Part V: Working with Dates and Times (20 minutes)","heading":"Common date and time functions","text":"Exercises:Convert ‘Date’ column ‘airquality’ dataset week day create new column ‘WeekDay’.Calculate number days first last measurements ‘airquality’ dataset.","code":"\n\n# Extracting parts of a date\nyear <- format(date_example, \"%Y\")\nmonth <- format(date_example, \"%m\")\nday <- format(date_example, \"%d\")\nprint(paste(\"Year:\", year, \"- Month:\", month, \"- Day:\", day))\n#> [1] \"Year: 2021 - Month: 01 - Day: 01\"\n\n# Working with time intervals\nstart_time <- as.POSIXct(\"2021-01-01 08:00:00\", tz = \"GMT\")\nend_time <- as.POSIXct(\"2021-01-01 10:00:00\", tz = \"GMT\")\ntime_diff <- difftime(end_time, start_time, units = \"hours\")\nprint(paste(\"Difference in hours:\", time_diff))\n#> [1] \"Difference in hours: 2\"\n\n# Loading a dataset with date and time data for exercises\n# Using the 'airquality' dataset from the 'datasets' package\ndata(airquality)\nairquality$Date <- as.Date(with(airquality, paste(1973, Month, Day, sep = \"-\")))\nprint(head(airquality))\n#>   Ozone Solar.R Wind Temp Month Day       Date\n#> 1    41     190  7.4   67     5   1 1973-05-01\n#> 2    36     118  8.0   72     5   2 1973-05-02\n#> 3    12     149 12.6   74     5   3 1973-05-03\n#> 4    18     313 11.5   62     5   4 1973-05-04\n#> 5    NA      NA 14.3   56     5   5 1973-05-05\n#> 6    28      NA 14.9   66     5   6 1973-05-06\ndata(airquality)\n\nairquality$Date <- as.Date(with(airquality, paste(1973, Month, Day, sep = \"-\")))\nprint(head(airquality))\n#>   Ozone Solar.R Wind Temp Month Day       Date\n#> 1    41     190  7.4   67     5   1 1973-05-01\n#> 2    36     118  8.0   72     5   2 1973-05-02\n#> 3    12     149 12.6   74     5   3 1973-05-03\n#> 4    18     313 11.5   62     5   4 1973-05-04\n#> 5    NA      NA 14.3   56     5   5 1973-05-05\n#> 6    28      NA 14.9   66     5   6 1973-05-06\nairquality$WeekDay <- weekdays(airquality$Date)\nprint(head(airquality))\n#>   Ozone Solar.R Wind Temp Month Day       Date   WeekDay\n#> 1    41     190  7.4   67     5   1 1973-05-01   Tuesday\n#> 2    36     118  8.0   72     5   2 1973-05-02 Wednesday\n#> 3    12     149 12.6   74     5   3 1973-05-03  Thursday\n#> 4    18     313 11.5   62     5   4 1973-05-04    Friday\n#> 5    NA      NA 14.3   56     5   5 1973-05-05  Saturday\n#> 6    28      NA 14.9   66     5   6 1973-05-06    Sunday\ndate_diff <- difftime(max(airquality$Date), min(airquality$Date), units = \"days\")\nprint(paste(\"Days between first and last measurement:\", date_diff))\n#> [1] \"Days between first and last measurement: 152\""},{"path":"workshop-1-suplementary-exercises.html","id":"workshop-1-suplementary-exercises","chapter":"Workshop 1: Suplementary Exercises","heading":"Workshop 1: Suplementary Exercises","text":"exercises https://intro2r.com/links explanation found , additionally, can read book chapters interested detailed explanation relates closely exercises. Now practice writing code script editor sourcing code R console. Let’s display help file function mean. script type help('mean') source code console. Notice help file displayed bottom right window (click ‘Help’ tab). Examine different components help file (especially examples section end help file). See Section 2.5 Introduction R book details using help functions. content displayed bottom right window context dependent. example write code plot(1:10) script source R console bottom right window display plot (don’t worry understanding R code right now, hopefully become clear later course!). Next, let’s practice creating variable assigning value variable. Take look Section 2.2 Introduction R book information prefer watch Objects R video. Create variable called first_num assign value 42. Click ‘Environment’ tab top right window display variable value. Now create another variable called first_char assign value \"first character\". Notice variable now also displayed ‘Environment’ along ’s value class (chr - short character class). Remove variable first_num environment using rm() function. Use code rm(first_num) . Check ‘Environment’ tab ensure variable removed. Alternatively, use ls() function list objects environment. Let’s see happens assign another value existing variable. Assign value \"second character\" variable first_char created Q6. Notice value changed ‘Environment’. display value first.char enter name variable console. Don’t forget save R script periodically! OK, let’s leave RStudio minute. Using favourite web browser, navigate R-project website explore links catch eye. Make sure find R manuals page user contributed documents section. Download manuals think might find useful (listed course manual) save computer (USB drive). Click ‘Search’ link R-Project website. Use ‘Rseek’ search term ‘mixed model p values’ (controversial subject!) explore anything looks interesting. Also experiment ‘R site search’ ‘Nabble R Forum’ links. Learning search help run problem using R acquired skill something get better time. One note caution, often find many different solutions solving problem R, written experienced R users others people less experience. Whichever solution choose make sure understand code thoroughly test make sure ’s want. OK, back RStudio. Sometimes may forget exact name function want use useful able search function names. example, want create design plot can remember name function word ‘plot’ . Use apropos() function list functions word plot name (see Section 2.5.1 Introduction R book). Look list figured correct function bring help file function (Hint: function name probably words ‘plot’ ‘design’ !). Another strategy use help.search() function search R’s help files. Search R help system instances character string ‘plot’. Take look Section 2.5.1 information. Also, see can figure narrow search searching ‘plot’ nlme package (hint: see help page help.search()). R’s working directory default location files read R, export R. Although won’t importing exporting files just yet (’s tomorrows job) ’s useful able determine current working directory . , read Section 1.7 Introduction R book introduce working directories figure display current working directory. ##Basic R operations {-}\nRead Chapter 2 help complete questions exercise. \n11. Let’s use R fancy calculator. Find natural log, log base 10, log base 2, square root natural antilog 12.43. See Section 2.1 Introduction R book information mathematical functions R. Don’t forget write code RStudio’s script editor source code console. Next, use R determine area circle diameter 20 cm assign result object called area_circle. can’t remember create assign objects see Section 2.2 watch video. Google friend can’t remember formula calculate area circle! Also, remember R already knows pi. Don’t worry ’re stumped feel free ask one instructors guidance. Now something little tricky. Calculate cube root 14 x 0.51. might need think creatively solution (hint: think exponents), remember R follows usual order mathematical operators might need use brackets code (see page ’ve never heard ). point question torture maths (please don’t stress!), get used writing mathematical equations R highlight order operations. Ok, ’re now ready explore one R’s basic (useful) data structures - vectors. vector sequence elements (components) data type (see Section 3.2.1 introduction vectors). Although technically correct might useful think vector something like single column spreadsheet. multitude ways create vectors R use concatenate function c() create vector called weight containing weight (kg) 10 children: 69, 62, 57, 59, 59, 64, 56, 66, 67, 66 (Section 2.3 watch video information). Now can useful stuff weight vector. Get R calculate mean, variance, standard deviation, range weights number children weight vector (see Section 2.3 details). Now read Section 2.4 R book learn work vectors. reading section able extract weights first five children using Positional indexes store weights new variable called first_five. Remember, need use square brackets [ ] extract (aka index, subset) elements variable. ’re now going use c() function create another vector called height containing height (cm) 10 children: 112, 102, 83, 84, 99, 90, 77, 112, 133, 112. Use summary() function summarise data height object. Extract height 2nd, 3rd, 9th 10th child assign heights variable called some_child (take look section Positional indexes R book ’re stuck). can also extract elements using Logical indexes. Let’s extract heights children less equal 99 cm assign variable called shorter_child. Now can use information weight height variables calculate body mass index (BMI) child. BMI calculated weight (kg) divided square height (meters). Store results calculation variable called bmi. Note: don’t need calculation child individually, can use vectors BMI equation – called vectorisation (see Section 2.4.4 Introduction R book). Now let’s practice useful skill - creating sequences (honestly …). Take look Section 2.3 R book (bit creating sequences) see myriad ways can create sequences R. Let’s use seq() function create sequence numbers ranging 0 1 steps 0.1 (also vector way) assign sequence variable called seq1. Next, see can figure create sequence 10 1 steps 0.5. Assign sequence variable called seq2 (Hint: may find useful include rev() function code). Let’s go sequence crazy! Generate following sequences. need experiment arguments rep() function generate sequences (see Section 2.3 clues):1 2 3 1 2 3 1 2 3“” “” “” “c” “c” “c” “e” “e” “e” “g” “g” “g”“” “c” “e” “g” “” “c” “e” “g” “” “c” “e” “g”1 1 1 2 2 2 3 3 3 1 1 1 2 2 2 3 3 31 1 1 1 1 2 2 2 2 3 3 3 4 4 57 7 7 7 2 2 2 8 1 1 1 1 1 Ok, back variable height created Q7. Let’s sort values height ascending order (shortest tallest) assign sorted vector new variable called height_sorted. Take look Section 2.4.3 R book see . Now sort heights descending order assign new vector name choice. Let’s give children names. Create new vector called child_name following names 10 children: \"Alfred\", \"Barbara\", \"James\", \"Jane\", \"John\", \"Judy\", \"Louise\", \"Mary\", \"Ronald\", \"William\". really useful (common) task order values one variable order another variable. need use order() function combination square bracket notation [ ]. peep Section 2.4.3 details. Create new variable called names_sort store names children ordered child height (shortest tallest). shortest? tallest child? ’re sure , please ask one instructors. Now order names children descending values weight assign result variable called weight_rev (Hint: perhaps include rev() function?). heaviest? lightest? Finally, list variables workspace created exercise. Remove variable seq1 workspace using rm() function. ","code":""},{"path":"workshop-1-suplementary-exercises-1.html","id":"workshop-1-suplementary-exercises-1","chapter":"Workshop 1: Suplementary Exercises","heading":"Workshop 1: Suplementary Exercises","text":"exercises https://intro2r.com/links explanation found , additionally, can read book chapters interested detailed explanation relates closely exercises. Now practice writing code script editor sourcing code R console. Let’s display help file function mean. script type help('mean') source code console. Notice help file displayed bottom right window (click ‘Help’ tab). Examine different components help file (especially examples section end help file). See Section 2.5 Introduction R book details using help functions. content displayed bottom right window context dependent. example write code plot(1:10) script source R console bottom right window display plot (don’t worry understanding R code right now, hopefully become clear later course!). Next, let’s practice creating variable assigning value variable. Take look Section 2.2 Introduction R book information prefer watch Objects R video. Create variable called first_num assign value 42. Click ‘Environment’ tab top right window display variable value. Now create another variable called first_char assign value \"first character\". Notice variable now also displayed ‘Environment’ along ’s value class (chr - short character class). Remove variable first_num environment using rm() function. Use code rm(first_num) . Check ‘Environment’ tab ensure variable removed. Alternatively, use ls() function list objects environment. Let’s see happens assign another value existing variable. Assign value \"second character\" variable first_char created Q6. Notice value changed ‘Environment’. display value first.char enter name variable console. Don’t forget save R script periodically! OK, let’s leave RStudio minute. Using favourite web browser, navigate R-project website explore links catch eye. Make sure find R manuals page user contributed documents section. Download manuals think might find useful (listed course manual) save computer (USB drive). Click ‘Search’ link R-Project website. Use ‘Rseek’ search term ‘mixed model p values’ (controversial subject!) explore anything looks interesting. Also experiment ‘R site search’ ‘Nabble R Forum’ links. Learning search help run problem using R acquired skill something get better time. One note caution, often find many different solutions solving problem R, written experienced R users others people less experience. Whichever solution choose make sure understand code thoroughly test make sure ’s want. OK, back RStudio. Sometimes may forget exact name function want use useful able search function names. example, want create design plot can remember name function word ‘plot’ . Use apropos() function list functions word plot name (see Section 2.5.1 Introduction R book). Look list figured correct function bring help file function (Hint: function name probably words ‘plot’ ‘design’ !). Another strategy use help.search() function search R’s help files. Search R help system instances character string ‘plot’. Take look Section 2.5.1 information. Also, see can figure narrow search searching ‘plot’ nlme package (hint: see help page help.search()). R’s working directory default location files read R, export R. Although won’t importing exporting files just yet (’s tomorrows job) ’s useful able determine current working directory . , read Section 1.7 Introduction R book introduce working directories figure display current working directory. ##Basic R operations {-}\nRead Chapter 2 help complete questions exercise. \n11. Let’s use R fancy calculator. Find natural log, log base 10, log base 2, square root natural antilog 12.43. See Section 2.1 Introduction R book information mathematical functions R. Don’t forget write code RStudio’s script editor source code console. Next, use R determine area circle diameter 20 cm assign result object called area_circle. can’t remember create assign objects see Section 2.2 watch video. Google friend can’t remember formula calculate area circle! Also, remember R already knows pi. Don’t worry ’re stumped feel free ask one instructors guidance. Now something little tricky. Calculate cube root 14 x 0.51. might need think creatively solution (hint: think exponents), remember R follows usual order mathematical operators might need use brackets code (see page ’ve never heard ). point question torture maths (please don’t stress!), get used writing mathematical equations R highlight order operations. Ok, ’re now ready explore one R’s basic (useful) data structures - vectors. vector sequence elements (components) data type (see Section 3.2.1 introduction vectors). Although technically correct might useful think vector something like single column spreadsheet. multitude ways create vectors R use concatenate function c() create vector called weight containing weight (kg) 10 children: 69, 62, 57, 59, 59, 64, 56, 66, 67, 66 (Section 2.3 watch video information). Now can useful stuff weight vector. Get R calculate mean, variance, standard deviation, range weights number children weight vector (see Section 2.3 details). Now read Section 2.4 R book learn work vectors. reading section able extract weights first five children using Positional indexes store weights new variable called first_five. Remember, need use square brackets [ ] extract (aka index, subset) elements variable. ’re now going use c() function create another vector called height containing height (cm) 10 children: 112, 102, 83, 84, 99, 90, 77, 112, 133, 112. Use summary() function summarise data height object. Extract height 2nd, 3rd, 9th 10th child assign heights variable called some_child (take look section Positional indexes R book ’re stuck). can also extract elements using Logical indexes. Let’s extract heights children less equal 99 cm assign variable called shorter_child. Now can use information weight height variables calculate body mass index (BMI) child. BMI calculated weight (kg) divided square height (meters). Store results calculation variable called bmi. Note: don’t need calculation child individually, can use vectors BMI equation – called vectorisation (see Section 2.4.4 Introduction R book). Now let’s practice useful skill - creating sequences (honestly …). Take look Section 2.3 R book (bit creating sequences) see myriad ways can create sequences R. Let’s use seq() function create sequence numbers ranging 0 1 steps 0.1 (also vector way) assign sequence variable called seq1. Next, see can figure create sequence 10 1 steps 0.5. Assign sequence variable called seq2 (Hint: may find useful include rev() function code). Let’s go sequence crazy! Generate following sequences. need experiment arguments rep() function generate sequences (see Section 2.3 clues):1 2 3 1 2 3 1 2 3“” “” “” “c” “c” “c” “e” “e” “e” “g” “g” “g”“” “c” “e” “g” “” “c” “e” “g” “” “c” “e” “g”1 1 1 2 2 2 3 3 3 1 1 1 2 2 2 3 3 31 1 1 1 1 2 2 2 2 3 3 3 4 4 57 7 7 7 2 2 2 8 1 1 1 1 1 Ok, back variable height created Q7. Let’s sort values height ascending order (shortest tallest) assign sorted vector new variable called height_sorted. Take look Section 2.4.3 R book see . Now sort heights descending order assign new vector name choice. Let’s give children names. Create new vector called child_name following names 10 children: \"Alfred\", \"Barbara\", \"James\", \"Jane\", \"John\", \"Judy\", \"Louise\", \"Mary\", \"Ronald\", \"William\". really useful (common) task order values one variable order another variable. need use order() function combination square bracket notation [ ]. peep Section 2.4.3 details. Create new variable called names_sort store names children ordered child height (shortest tallest). shortest? tallest child? ’re sure , please ask one instructors. Now order names children descending values weight assign result variable called weight_rev (Hint: perhaps include rev() function?). heaviest? lightest? Finally, list variables workspace created exercise. Remove variable seq1 workspace using rm() function. Almost ! R, missing values usually represented NA. Missing data can tricky deal R (statistics generally) cause surprising behaviour using functions. Take look Section 2.4.5 R book information missing values. explore little let’s create vector called mydata values 2, 4, 1, 6, 8, 5, NA, 4, 7. Notice value 7th element mydata missing. Now use mean() function calculate mean values mydata. R return? Confused? Next, take look help page function mean(). Can figure alter use mean() function calculate mean without missing value? Almost ! R, missing values usually represented NA. Missing data can tricky deal R (statistics generally) cause surprising behaviour using functions. Take look Section 2.4.5 R book information missing values. explore little let’s create vector called mydata values 2, 4, 1, 6, 8, 5, NA, 4, 7. Notice value 7th element mydata missing. Now use mean() function calculate mean values mydata. R return? Confused? Next, take look help page function mean(). Can figure alter use mean() function calculate mean without missing value? ","code":""},{"path":"part-i-advanced-data-manipulation-with-dplyr-30-minutes.html","id":"part-i-advanced-data-manipulation-with-dplyr-30-minutes","chapter":"Part I: Advanced Data Manipulation with dplyr (30 minutes)","heading":"Part I: Advanced Data Manipulation with dplyr (30 minutes)","text":"","code":""},{"path":"part-i-advanced-data-manipulation-with-dplyr-30-minutes.html","id":"grouping-and-summarizing-data","chapter":"Part I: Advanced Data Manipulation with dplyr (30 minutes)","heading":"Grouping and summarizing data","text":"Exercise:Group ‘mtcars’ dataset ‘gear’ calculate average horsepower (‘hp’) gear group.","code":"\n# Loading the dplyr package\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n# Using the 'mtcars' dataset\ndata(mtcars)\n\n# Example: Grouping by 'cyl' (number of cylinders) and calculating mean mpg (miles per gallon)\ngrouped_data <- mtcars %>%\n  group_by(cyl) %>%\n  summarize(mean_mpg = mean(mpg))\nprint(grouped_data)\n#> # A tibble: 3 × 2\n#>     cyl mean_mpg\n#>   <dbl>    <dbl>\n#> 1     4     26.7\n#> 2     6     19.7\n#> 3     8     15.1"},{"path":"part-i-advanced-data-manipulation-with-dplyr-30-minutes.html","id":"joining-and-merging-datasets","chapter":"Part I: Advanced Data Manipulation with dplyr (30 minutes)","heading":"Joining and merging datasets","text":"Exercise:Create new dataframe subset columns ‘iris’ merge original ‘iris’ dataset based common column.","code":"\n# Creating a sample dataset to join with 'mtcars'\ncar_names <- data.frame(model = rownames(mtcars), car_type = rep(c(\"Type A\", \"Type B\", \"Type C\"), length.out = nrow(mtcars)))\n\n# Converting row names of 'mtcars' to a column\nmtcars$model <- rownames(mtcars)\n\n# Example: Joining 'mtcars' and 'car_names'\njoined_data <- left_join(mtcars, car_names, by = \"model\")\nprint(head(joined_data))\n#>    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n#> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n#>               model car_type\n#> 1         Mazda RX4   Type A\n#> 2     Mazda RX4 Wag   Type B\n#> 3        Datsun 710   Type C\n#> 4    Hornet 4 Drive   Type A\n#> 5 Hornet Sportabout   Type B\n#> 6           Valiant   Type C"},{"path":"part-ii-text-data-processing-30-minutes.html","id":"part-ii-text-data-processing-30-minutes","chapter":"Part II: Text Data Processing (30 minutes)","heading":"Part II: Text Data Processing (30 minutes)","text":"","code":""},{"path":"part-ii-text-data-processing-30-minutes.html","id":"manipulating-and-analyzing-text-data-using-regular-expressions","chapter":"Part II: Text Data Processing (30 minutes)","heading":"Manipulating and analyzing text data using regular expressions","text":"Exercise:Write regular expression find words starting ‘b’ given text.","code":"\n# --- Part II: Text Data Processing (30 minutes) ---\n\n# Load necessary libraries\nlibrary(stringr)\n\n## Manipulating and analyzing text data using regular expressions\n\n# Example: Extracting email addresses from a string\ntext <- \"Contact us at support@example.com or feedback@example.net\"\nemails <- str_extract_all(text, \"[[:alnum:]_.]+@[[:alnum:]]+\\\\.[[:alpha:]]{2,}\")\nprint(emails)\n#> [[1]]\n#> [1] \"support@example.com\"  \"feedback@example.net\""},{"path":"part-ii-text-data-processing-30-minutes.html","id":"text-mining-basics","chapter":"Part II: Text Data Processing (30 minutes)","heading":"Text mining basics","text":"Exercise:Create corpus text data compute term frequency-inverse document frequency (tf-idf) matrix.","code":"\n\n# Load the 'tm' package for text mining\nlibrary(tm)\n#> Loading required package: NLP\n\n# Example: Basic text mining with a simple corpus\ndocs <- Corpus(VectorSource(c(\"Text mining is awesome\", \"R is a versatile tool for text analysis\")))\ndtm <- DocumentTermMatrix(docs)\ninspect(dtm)\n#> <<DocumentTermMatrix (documents: 2, terms: 7)>>\n#> Non-/sparse entries: 8/6\n#> Sparsity           : 43%\n#> Maximal term length: 9\n#> Weighting          : term frequency (tf)\n#> Sample             :\n#>     Terms\n#> Docs analysis awesome for mining text tool versatile\n#>    1        0       1   0      1    1    0         0\n#>    2        1       0   1      0    1    1         1"},{"path":"part-iii-building-predictive-models-30-minutes.html","id":"part-iii-building-predictive-models-30-minutes","chapter":"Part III: Building Predictive Models (30 minutes)","heading":"Part III: Building Predictive Models (30 minutes)","text":"","code":""},{"path":"part-iii-building-predictive-models-30-minutes.html","id":"introduction-to-machine-learning-in-r","chapter":"Part III: Building Predictive Models (30 minutes)","heading":"Introduction to machine learning in R","text":"Brief overview machine learning: Machine learning R involves using statistical techniques enable computers improve tasks experience. encompasses variety techniques classification, regression, clustering, .Exercise:Load different dataset partition training testing sets.","code":"\n# Load necessary libraries\n#install.packages(\"caret\")\nlibrary(caret)\n#> Loading required package: ggplot2\n#> Loading required package: lattice\n\n\n# Example: Splitting a dataset into training and testing sets\ndata(iris)\nset.seed(123) # Setting seed for reproducibility\ntrainingIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)\ntrainingData <- iris[trainingIndex, ]\ntestingData <- iris[-trainingIndex, ]"},{"path":"part-iii-building-predictive-models-30-minutes.html","id":"creating-predictive-models-with-caret","chapter":"Part III: Building Predictive Models (30 minutes)","heading":"Creating predictive models with caret","text":"Exercise:\n2. Build predictive model another dataset evaluate performance.basic structure Shiny app involves two main parts:user interface (UI) script, controls layout appearance app.server script, contains instructions build rebuild app based user input.","code":"\n\n# Example: Building a predictive model for the iris dataset\nmodel <- train(Species ~ ., data = trainingData, method = \"rpart\")\nprint(model)\n#> CART \n#> \n#> 120 samples\n#>   4 predictor\n#>   3 classes: 'setosa', 'versicolor', 'virginica' \n#> \n#> No pre-processing\n#> Resampling: Bootstrapped (25 reps) \n#> Summary of sample sizes: 120, 120, 120, 120, 120, 120, ... \n#> Resampling results across tuning parameters:\n#> \n#>   cp    Accuracy   Kappa    \n#>   0.00  0.9398492  0.9086993\n#>   0.45  0.7426390  0.6253355\n#>   0.50  0.5557896  0.3665192\n#> \n#> Accuracy was used to select the optimal model using\n#>  the largest value.\n#> The final value used for the model was cp = 0.\n\n# Predicting using the model\npredictions <- predict(model, testingData)\nconfusionMatrix(predictions, testingData$Species)\n#> Confusion Matrix and Statistics\n#> \n#>             Reference\n#> Prediction   setosa versicolor virginica\n#>   setosa         10          0         0\n#>   versicolor      0         10         2\n#>   virginica       0          0         8\n#> \n#> Overall Statistics\n#>                                           \n#>                Accuracy : 0.9333          \n#>                  95% CI : (0.7793, 0.9918)\n#>     No Information Rate : 0.3333          \n#>     P-Value [Acc > NIR] : 8.747e-12       \n#>                                           \n#>                   Kappa : 0.9             \n#>                                           \n#>  Mcnemar's Test P-Value : NA              \n#> \n#> Statistics by Class:\n#> \n#>                      Class: setosa Class: versicolor\n#> Sensitivity                 1.0000            1.0000\n#> Specificity                 1.0000            0.9000\n#> Pos Pred Value              1.0000            0.8333\n#> Neg Pred Value              1.0000            1.0000\n#> Prevalence                  0.3333            0.3333\n#> Detection Rate              0.3333            0.3333\n#> Detection Prevalence        0.3333            0.4000\n#> Balanced Accuracy           1.0000            0.9500\n#>                      Class: virginica\n#> Sensitivity                    0.8000\n#> Specificity                    1.0000\n#> Pos Pred Value                 1.0000\n#> Neg Pred Value                 0.9091\n#> Prevalence                     0.3333\n#> Detection Rate                 0.2667\n#> Detection Prevalence           0.2667\n#> Balanced Accuracy              0.9000\n\n<!--chapter:end:13-Advanced-R-Part3.Rmd-->\n\n# Part IV: Interactive Dashboards with Shiny (30 minutes) {-}\n## Introduction to Shiny for building web-based data dashboards {-}\n\nShiny is an R package that makes it easy to build interactive web applications (apps) straight from R. It allows you to turn analyses into interactive web applications without requiring HTML, CSS, or JavaScript knowledge.\n\n\n```r\n# Load the Shiny package\n#install.packages(\"shiny\")\nlibrary(shiny)"},{"path":"part-iii-building-predictive-models-30-minutes.html","id":"creating-a-simple-shiny-app","chapter":"Part III: Building Predictive Models (30 minutes)","heading":"Creating a simple Shiny app","text":"UI Component: UI sliderInput selecting mpg range tableOutput display filtered data.Server Logic: reactive function creates reactive subset mtcars based selected mpg range. renderTable function renders filtered data table main panel.Running App: Shiny app, shinyApp(ui = ui, server = server) runs app.Exercise:Modify example Shiny app include dataset choice create different type plot.Modify example Shiny app include dataset choice create different type plot.Add additional input options, like checkboxes dropdown menus, manipulate plot.Add additional input options, like checkboxes dropdown menus, manipulate plot.","code":"\n\n# Example: A simple Shiny app for displaying a plot\n\n# Define UI\nui <- fluidPage(\n  titlePanel(\"Simple Shiny App\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"num\", \"Number of bins:\", \n                  min = 1, max = 50, value = 30)\n    ),\n    mainPanel(\n       plotOutput(\"distPlot\")\n    )\n  )\n)\n\n# Define server logic\nserver <- function(input, output) {\n  output$distPlot <- renderPlot({\n    x <- faithful$eruptions\n    bins <- seq(min(x), max(x), length.out = input$num + 1)\n    hist(x, breaks = bins, col = 'darkgray', border = 'white')\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)\n\n# Define UI\nui <- fluidPage(\n  titlePanel(\"Data Filtering App\"),\n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(\"mpgRange\", \"Miles per Gallon (mpg):\",\n                  min = min(mtcars$mpg), max = max(mtcars$mpg),\n                  value = c(min(mtcars$mpg), max(mtcars$mpg))\n      )\n    ),\n    mainPanel(\n      tableOutput(\"filteredData\")\n    )\n  )\n)\n\n# Define server logic\nserver <- function(input, output) {\n  filteredData <- reactive({\n    mtcars[mtcars$mpg >= input$mpgRange[1] & mtcars$mpg <= input$mpgRange[2], ]\n  })\n\n  output$filteredData <- renderTable({\n    filteredData()\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)"},{"path":"optional-part-v-version-control-and-collaboration-10-minutes.html","id":"optional-part-v-version-control-and-collaboration-10-minutes","chapter":"(Optional) Part V: Version Control and Collaboration (10 minutes)","heading":"(Optional) Part V: Version Control and Collaboration (10 minutes)","text":"","code":""},{"path":"optional-part-v-version-control-and-collaboration-10-minutes.html","id":"using-git-and-github-for-version-control-and-collaboration-in-r-projects","chapter":"(Optional) Part V: Version Control and Collaboration (10 minutes)","heading":"Using Git and GitHub for version control and collaboration in R projects","text":"Git distributed version control system helps track changes source code software development. GitHub cloud-based hosting service lets manage Git repositories.Integrating Git R:\n1. Install Git set GitHub account.\n2. Configure Git username email.\n- Use Git Bash terminal:\ngit config –global user.name “Name”\ngit config –global user.email “.email@example.com”Initialize Git repository R project:\nRStudio, start new project select option create Git repository.\nRStudio, start new project select option create Git repository.Basic Git commands:\ngit init: Initialize new Git repository.\ngit status: Check status changes.\ngit add: Add files staging area.\ngit commit: Commit changes repository.\ngit push: Push changes remote repository like GitHub.\ngit pull: Pull updates remote repository.\ngit init: Initialize new Git repository.git status: Check status changes.git add: Add files staging area.git commit: Commit changes repository.git push: Push changes remote repository like GitHub.git pull: Pull updates remote repository.Collaborating GitHub:\nFork clone repositories.\nCreate branches features fixes.\nUse pull requests code reviews.\nMerge changes main branch.\nFork clone repositories.Create branches features fixes.Use pull requests code reviews.Merge changes main branch.Exercise:Create new R project Git repository.Make changes project, commit , push GitHub repository.Collaborate colleague friend fork repository submit pull request.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
